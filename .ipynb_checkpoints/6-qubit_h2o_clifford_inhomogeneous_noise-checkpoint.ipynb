{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5c54421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, random\n",
    "import numpy as np\n",
    "# import pennylane as qml\n",
    "# from qiskit import Aer, transpile, execute\n",
    "from qiskit.circuit import QuantumCircuit\n",
    "from qiskit.quantum_info import random_clifford, Pauli, Statevector\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(precision=6, edgeitems=10, linewidth=150, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdc907b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiskit\n",
    "import itertools\n",
    "from qiskit import *\n",
    "from qiskit.quantum_info import Clifford, random_clifford\n",
    "from qiskit.synthesis import synth_clifford_full\n",
    "from qiskit.quantum_info import hellinger_fidelity as hf\n",
    "\n",
    "from utils.pauli_checks import ChecksFinder, add_pauli_checks, add_meas_pauli_checks, add_linear_meas_pauli_checks,  search_for_pauli_list\n",
    "from utils.pauli_checks import gen_initial_layout, gen_final_layout, complete_postprocess, filter_results\n",
    "\n",
    "from utils.utils import norm_dict, total_counts\n",
    "# from utils.vqe_utils import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c227eedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qiskit.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60b0f6fc-4492-437f-b8dd-f0d7f2a50df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "print(qiskit.version.get_version_info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76c9417",
   "metadata": {},
   "source": [
    "#### I. Calibrating $\\tilde{f}$ in the noisy Clifford channel using hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e6026e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trials = 10000\n",
    "num_qubits = 6\n",
    "def calibration_circuit(Clifford):\n",
    "    qc = QuantumCircuit(num_qubits)\n",
    "    \n",
    "    clifford_circuit = Clifford.to_circuit()\n",
    "    # qc.compose(clifford_circuit, qubits=[0,1,2,3], inplace=True)\n",
    "    qc.compose(clifford_circuit, qubits=range(num_qubits), inplace=True)\n",
    "    \n",
    "    qc.measure_all()\n",
    "    return qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30a3e41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cali_C_list = []\n",
    "for i in range(total_trials):\n",
    "    # Clifford = random_clifford(4)\n",
    "    Clifford = random_clifford(num_qubits)\n",
    "    cali_C_list.append(Clifford)\n",
    "    \n",
    "cali_circs = []\n",
    "for i in range(total_trials):\n",
    "    circuit = calibration_circuit(cali_C_list[i])\n",
    "    cali_circs.append(circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7ea06fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ┌───┐┌───┐                                 ┌───┐┌───┐┌───┐     »\n",
      "   q_0: ──X──┤ X ├┤ S ├──────X──────────────────────────┤ X ├┤ H ├┤ S ├──X──»\n",
      "          │  └─┬─┘├───┤┌───┐ │           ┌───┐┌───┐     └─┬─┘└───┘└───┘  │  »\n",
      "   q_1: ──┼────■──┤ X ├┤ H ├─┼───■───────┤ X ├┤ S ├───────┼──────────────┼──»\n",
      "          │       └─┬─┘└───┘ │ ┌─┴─┐┌───┐└─┬─┘└───┘┌───┐  │              │  »\n",
      "   q_2: ──X────■────■────────┼─┤ X ├┤ X ├──┼────■──┤ Z ├──┼──────────────┼──»\n",
      "        ┌───┐  │  ┌───┐      │ └───┘└─┬─┘  │    │  ├───┤  │  ┌───┐       │  »\n",
      "   q_3: ┤ H ├──┼──┤ X ├──────┼────────■────┼────┼──┤ H ├──┼──┤ X ├──■────X──»\n",
      "        ├───┤┌─┴─┐└─┬─┘      │             │    │  └───┘  │  └─┬─┘┌─┴─┐     »\n",
      "   q_4: ┤ S ├┤ X ├──┼────────X─────────────■────┼─────────■────┼──┤ X ├──■──»\n",
      "        ├───┤└───┘  │                         ┌─┴─┐            │  └───┘┌─┴─┐»\n",
      "   q_5: ┤ H ├───────■─────────────────────────┤ X ├────────────■───────┤ X ├»\n",
      "        └───┘                                 └───┘                    └───┘»\n",
      "meas: 6/════════════════════════════════════════════════════════════════════»\n",
      "                                                                            »\n",
      "«                            ┌───┐          ┌───┐┌───┐                   ░ ┌─┐»\n",
      "«   q_0: ────────────────────┤ X ├──■───────┤ X ├┤ X ├───────────────────░─┤M├»\n",
      "«        ┌───┐               └─┬─┘┌─┴─┐┌───┐└─┬─┘├───┤        ┌───┐┌───┐ ░ └╥┘»\n",
      "«   q_1: ┤ X ├─────────────────┼──┤ X ├┤ H ├──■──┤ S ├─X───■──┤ S ├┤ Y ├─░──╫─»\n",
      "«        └─┬─┘                 │  └───┘└───┘     └───┘ │   │  └───┘└───┘ ░  ║ »\n",
      "«   q_2: ──┼───────────────────┼───────────────────────┼───┼─────────────░──╫─»\n",
      "«          │  ┌───┐┌───┐       │                       │   │             ░  ║ »\n",
      "«   q_3: ──■──┤ X ├┤ Z ├───────┼───────────────────────┼───┼─────────────░──╫─»\n",
      "«        ┌───┐└─┬─┘└───┘       │                       │   │             ░  ║ »\n",
      "«   q_4: ┤ Z ├──┼──────────────┼───────────────────────┼───┼─────────────░──╫─»\n",
      "«        ├───┤  │  ┌───┐┌───┐  │                       │ ┌─┴─┐┌───┐      ░  ║ »\n",
      "«   q_5: ┤ H ├──■──┤ S ├┤ H ├──■───────────────────────X─┤ X ├┤ Z ├──────░──╫─»\n",
      "«        └───┘     └───┘└───┘                            └───┘└───┘      ░  ║ »\n",
      "«meas: 6/═══════════════════════════════════════════════════════════════════╩═»\n",
      "«                                                                           0 »\n",
      "«                       \n",
      "«   q_0: ───────────────\n",
      "«        ┌─┐            \n",
      "«   q_1: ┤M├────────────\n",
      "«        └╥┘┌─┐         \n",
      "«   q_2: ─╫─┤M├─────────\n",
      "«         ║ └╥┘┌─┐      \n",
      "«   q_3: ─╫──╫─┤M├──────\n",
      "«         ║  ║ └╥┘┌─┐   \n",
      "«   q_4: ─╫──╫──╫─┤M├───\n",
      "«         ║  ║  ║ └╥┘┌─┐\n",
      "«   q_5: ─╫──╫──╫──╫─┤M├\n",
      "«         ║  ║  ║  ║ └╥┘\n",
      "«meas: 6/═╩══╩══╩══╩══╩═\n",
      "«         1  2  3  4  5 \n"
     ]
    }
   ],
   "source": [
    "print(cali_circs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c80a9a",
   "metadata": {},
   "source": [
    "Set noise model and topolgoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "118055dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from qiskit_ibm_runtime import Session, Options, SamplerV2 as Sampler\n",
    "# from qiskit_ibm_runtime import Session, Sampler, Options\n",
    "# from qiskit_ibm_runtime.fake_provider import *\n",
    "# from qiskit_aer import AerSimulator\n",
    "# import qiskit_aer.noise as noise\n",
    "# from itertools import combinations\n",
    "\n",
    "# #service = QiskitRuntimeService(channel=\"ibm_quantum\", instance=\"ibm-q-ornl/anl/chm185\")\n",
    "# # service = QiskitRuntimeService(channel=\"ibm_quantum\", instance=\"ibm-q/open/main\")\n",
    "\n",
    "# # Make a noise model\n",
    "# fake_backend = FakeCairo()\n",
    "# # noise_model = NoiseModel.from_backend(fake_backend)\n",
    "\n",
    "# prob_1 = 0.002  # 1-qubit gate\n",
    "# prob_2 = 0.02   # 2-qubit gate\n",
    "\n",
    "# error_1 = noise.depolarizing_error(prob_1, 1)\n",
    "# error_2 = noise.depolarizing_error(prob_2, 2)\n",
    "\n",
    "# noise_model = noise.NoiseModel()\n",
    "# noise_model.add_all_qubit_quantum_error(error_1, ['u1', 'u2', 'u3', 'sx', 'x'])\n",
    "# noise_model.add_all_qubit_quantum_error(error_2, ['cx'])\n",
    "\n",
    "# options = Options(optimization_level=2, resilience_level=1) # choose the proper levels on hardware\n",
    "# options.simulator = {\n",
    "#     \"noise_model\": noise_model,\n",
    "#     \"basis_gates\": fake_backend.configuration().basis_gates,\n",
    "#     # \"coupling_map\": fake_backend.configuration().coupling_map,\n",
    "#     \"seed_simulator\": 42\n",
    "# }\n",
    "\n",
    "# #backend = service.get_backend(\"\") \n",
    "# #backend = \"ibmq_qasm_simulator\" # use the simulator for now\n",
    "# backend = AerSimulator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910a29d1",
   "metadata": {},
   "source": [
    "inhomogeneous error rates (across qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "895e5551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-qubit error rates: [0.002248 0.001931 0.002324 0.002762 0.001883 0.001883]\n",
      "2-qubit error rates: [0.027896 0.023837 0.017653 0.022713 0.017683 0.017671 0.02121  0.010434 0.011375 0.017189 0.014936 0.021571 0.01546  0.012938 0.027328]\n"
     ]
    }
   ],
   "source": [
    "# from qiskit_ibm_runtime import Session, Options, SamplerV2 as Sampler\n",
    "from qiskit_ibm_runtime import Session, Sampler, Options\n",
    "from qiskit_ibm_runtime.fake_provider import *\n",
    "from qiskit_aer import AerSimulator\n",
    "import qiskit_aer.noise as noise\n",
    "from itertools import combinations\n",
    "\n",
    "# Set up the fake backend\n",
    "fake_backend = FakeCairo()\n",
    "\n",
    "# Specify noisy qubits and their pairs\n",
    "noisy_qubits = [0, 1, 2, 3, 4, 5]\n",
    "noisy_pairs = list(combinations(noisy_qubits, 2))\n",
    "\n",
    "# Define mean and standard deviation for error rates\n",
    "mean_prob_1, std_dev_1 = 0.002, 0.0005  # Mean and standard deviation for 1-qubit gate error rates\n",
    "mean_prob_2, std_dev_2 = 0.02, 0.005   # Mean and standard deviation for 2-qubit gate error rates\n",
    "\n",
    "# Generate random error rates following a Gaussian distribution\n",
    "np.random.seed(42)  # For reproducibility\n",
    "error_rates_1 = np.random.normal(mean_prob_1, std_dev_1, len(noisy_qubits))\n",
    "error_rates_2 = np.random.normal(mean_prob_2, std_dev_2, len(noisy_pairs))\n",
    "\n",
    "# Ensure error rates are within a reasonable range (e.g., non-negative)\n",
    "error_rates_1 = np.clip(error_rates_1, 0, 1)\n",
    "error_rates_2 = np.clip(error_rates_2, 0, 1)\n",
    "\n",
    "print(\"1-qubit error rates:\", error_rates_1)\n",
    "print(\"2-qubit error rates:\", error_rates_2)\n",
    "\n",
    "# Create a noise model\n",
    "noise_model = noise.NoiseModel()\n",
    "\n",
    "# Assign error rates in ascending order\n",
    "for i, noisy_qbt in enumerate(noisy_qubits):\n",
    "    error_1 = noise.depolarizing_error(error_rates_1[i], 1)\n",
    "    noise_model.add_quantum_error(error_1, ['u1', 'u2', 'u3', 'sx', 'x'], [noisy_qbt])\n",
    "\n",
    "for i, noisy_pair in enumerate(noisy_pairs):\n",
    "    error_2 = noise.depolarizing_error(error_rates_2[i], 2)\n",
    "    noise_model.add_quantum_error(error_2, ['cx'], list(noisy_pair))\n",
    "    noise_model.add_quantum_error(error_2, ['cx'], list(reversed(noisy_pair)))\n",
    "\n",
    "options = Options(optimization_level=2, resilience_level=1) # choose the proper levels on hardware\n",
    "options.simulator = {\n",
    "    \"noise_model\": noise_model,\n",
    "    \"basis_gates\": fake_backend.configuration().basis_gates,\n",
    "#     \"coupling_map\": fake_backend.configuration().coupling_map,\n",
    "    \"seed_simulator\": 42\n",
    "}\n",
    "#backend = service.get_backend(\"\") \n",
    "# backend = \"ibmq_qasm_simulator\" # use the simulator for now\n",
    "backend = AerSimulator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bf91f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoiseModel:\n",
      "  Basis gates: ['cx', 'id', 'rz', 'sx', 'u1', 'u2', 'u3', 'x']\n",
      "  Instructions with noise: ['x', 'sx', 'u1', 'u3', 'cx', 'u2']\n",
      "  Qubits with noise: [0, 1, 2, 3, 4, 5]\n",
      "  Specific qubit errors: [('u1', (0,)), ('u1', (1,)), ('u1', (2,)), ('u1', (3,)), ('u1', (4,)), ('u1', (5,)), ('u2', (0,)), ('u2', (1,)), ('u2', (2,)), ('u2', (3,)), ('u2', (4,)), ('u2', (5,)), ('u3', (0,)), ('u3', (1,)), ('u3', (2,)), ('u3', (3,)), ('u3', (4,)), ('u3', (5,)), ('sx', (0,)), ('sx', (1,)), ('sx', (2,)), ('sx', (3,)), ('sx', (4,)), ('sx', (5,)), ('x', (0,)), ('x', (1,)), ('x', (2,)), ('x', (3,)), ('x', (4,)), ('x', (5,)), ('cx', (0, 1)), ('cx', (1, 0)), ('cx', (0, 2)), ('cx', (2, 0)), ('cx', (0, 3)), ('cx', (3, 0)), ('cx', (0, 4)), ('cx', (4, 0)), ('cx', (0, 5)), ('cx', (5, 0)), ('cx', (1, 2)), ('cx', (2, 1)), ('cx', (1, 3)), ('cx', (3, 1)), ('cx', (1, 4)), ('cx', (4, 1)), ('cx', (1, 5)), ('cx', (5, 1)), ('cx', (2, 3)), ('cx', (3, 2)), ('cx', (2, 4)), ('cx', (4, 2)), ('cx', (2, 5)), ('cx', (5, 2)), ('cx', (3, 4)), ('cx', (4, 3)), ('cx', (3, 5)), ('cx', (5, 3)), ('cx', (4, 5)), ('cx', (5, 4))]\n"
     ]
    }
   ],
   "source": [
    "print(noise_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b29169a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/celsloaner/opt/anaconda3/envs/pcs_zne/lib/python3.9/site-packages/qiskit_ibm_runtime/session.py:157: UserWarning: Session is not supported in local testing mode or when using a simulator.\n",
      "  warnings.warn(\n",
      "/var/folders/b4/nbfyyzvd3tlcp6vv5xyc9wpw0000gq/T/ipykernel_35046/4135206114.py:2: DeprecationWarning: The Sampler and Estimator V1 primitives have been deprecated as of qiskit-ibm-runtime 0.23.0 and will be removed no sooner than 3 months after the release date. Please use the V2 Primitives. See the `V2 migration guide <https://docs.quantum.ibm.com/api/migration-guides/v2-primitives>`_. for more details\n",
      "  sampler = Sampler(session=session, options=options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: c3cdda67-53b7-4baa-bd44-ae150a6ce671\n",
      ">>> Job Status: JobStatus.RUNNING\n"
     ]
    }
   ],
   "source": [
    "with Session(backend=backend) as session:\n",
    "    sampler = Sampler(session=session, options=options)\n",
    "    \n",
    "    # define physical qubits to be used in the layout arguement\n",
    "    job = sampler.run(cali_circs, shots=1024, initial_layout=[])\n",
    "    print(f\"Job ID: {job.job_id()}\")\n",
    "    print(f\">>> Job Status: {job.status()}\")\n",
    "    \n",
    "    result = job.result()\n",
    "    \n",
    "    # Close the session only if all jobs are finished\n",
    "    # and you don't need to run more in the session.\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c97a075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cali_b_lists = []\n",
    "\n",
    "for i in range(total_trials):\n",
    "    di = {}\n",
    "    for key in list(result.quasi_dists[i].binary_probabilities().keys()):\n",
    "        di.update({key[:num_qubits]: result.quasi_dists[i].binary_probabilities().get(key)})\n",
    "    cali_b_lists.append(di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37913fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cali_b_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5822a2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'111011': 0.0009765625,\n",
       " '100010': 0.001953125,\n",
       " '110101': 0.0009765625,\n",
       " '001111': 0.00390625,\n",
       " '111000': 0.00390625,\n",
       " '110000': 0.0009765625,\n",
       " '110110': 0.00390625,\n",
       " '101001': 0.0029296875,\n",
       " '011010': 0.0234375,\n",
       " '111001': 0.021484375,\n",
       " '100001': 0.00390625,\n",
       " '010011': 0.00390625,\n",
       " '000010': 0.0009765625,\n",
       " '011110': 0.0029296875,\n",
       " '011000': 0.0029296875,\n",
       " '110011': 0.001953125,\n",
       " '101101': 0.03125,\n",
       " '101010': 0.0029296875,\n",
       " '000100': 0.005859375,\n",
       " '100111': 0.0009765625,\n",
       " '101100': 0.0048828125,\n",
       " '000011': 0.03125,\n",
       " '111101': 0.001953125,\n",
       " '011001': 0.03515625,\n",
       " '110111': 0.03125,\n",
       " '001110': 0.0234375,\n",
       " '000101': 0.0234375,\n",
       " '000000': 0.0263671875,\n",
       " '110001': 0.0205078125,\n",
       " '011101': 0.00390625,\n",
       " '000110': 0.025390625,\n",
       " '000111': 0.00390625,\n",
       " '010100': 0.03125,\n",
       " '011011': 0.0029296875,\n",
       " '001011': 0.0263671875,\n",
       " '001001': 0.00390625,\n",
       " '100100': 0.00390625,\n",
       " '111110': 0.0048828125,\n",
       " '100000': 0.037109375,\n",
       " '011111': 0.029296875,\n",
       " '010111': 0.029296875,\n",
       " '010110': 0.001953125,\n",
       " '010001': 0.03125,\n",
       " '110010': 0.0263671875,\n",
       " '101011': 0.0263671875,\n",
       " '100011': 0.0263671875,\n",
       " '111100': 0.0302734375,\n",
       " '001000': 0.0302734375,\n",
       " '111010': 0.0224609375,\n",
       " '001101': 0.0205078125,\n",
       " '101110': 0.0283203125,\n",
       " '110100': 0.01953125,\n",
       " '010101': 0.00390625,\n",
       " '001010': 0.0068359375,\n",
       " '001100': 0.001953125,\n",
       " '101000': 0.0361328125,\n",
       " '000001': 0.0029296875,\n",
       " '100101': 0.02734375,\n",
       " '111111': 0.0341796875,\n",
       " '010010': 0.037109375,\n",
       " '101111': 0.00390625,\n",
       " '011100': 0.0234375,\n",
       " '010000': 0.0029296875,\n",
       " '100110': 0.033203125}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cali_b_lists[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdea9a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrating_f(cali_b_lists, cali_C_list, num_qubits):\n",
    "    d = 2**num_qubits\n",
    "    num_snapshots = len(cali_C_list)\n",
    "    \n",
    "    f_tilde = 0.\n",
    "    for b_dict, clifford in zip(cali_b_lists, cali_C_list):\n",
    "        F = computing_F(b_dict, clifford, num_qubits)\n",
    "        f_tilde += np.real((d*F - 1) / (d - 1))\n",
    "    \n",
    "    return f_tilde / num_snapshots\n",
    "\n",
    "\n",
    "def computing_F(b_dict, clifford, num_qubits):\n",
    "    zero_state = state_reconstruction('0'*num_qubits)\n",
    "    U = clifford.to_matrix()\n",
    "    \n",
    "    F = 0. + 0.j\n",
    "    denom = 0.\n",
    "    for b_state in list(b_dict.keys()):\n",
    "        F += np.trace(zero_state @ U.T.conj() @ state_reconstruction(b_state) @ U) * b_dict.get(b_state)\n",
    "        denom += b_dict.get(b_state)\n",
    "    return F / denom\n",
    "\n",
    "\n",
    "def state_reconstruction(b_str: str):\n",
    "    '''\n",
    "    '''\n",
    "    zero_state = np.array([[1,0],[0,0]])\n",
    "    one_state = np.array([[0,0], [0,1]])\n",
    "    rho = [1]\n",
    "    for i in b_str:\n",
    "        state_i = zero_state if i=='0' else one_state\n",
    "        rho = np.kron(rho, state_i)\n",
    "    return rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46183d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The calibrated f_tilde is 0.01153048735119043; while the noiseless reference is 0.015384615384615385\n",
      "CPU times: user 24min 8s, sys: 6min 45s, total: 30min 54s\n",
      "Wall time: 7min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "f_tilde = calibrating_f(cali_b_lists, cali_C_list, num_qubits)\n",
    "print(f'The calibrated f_tilde is {f_tilde}; while the noiseless reference is {1/(2**num_qubits+1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf8b013",
   "metadata": {},
   "source": [
    "#### II. Perform the standard shadow experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2054f038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit import QuantumCircuit, Parameter, ParameterVector\n",
    "\n",
    "def construct_qcc_circuit(entanglers: list, truncation=None):\n",
    "    '''This function defines the QCC ansatz circuit for VQE. Here we construct exponential blocks using\n",
    "    entanglers from QMF state as a proof of principle demonstration.\n",
    "    \n",
    "    Args:\n",
    "        entanglers: list storing Pauli words for construction of qcc_circuit.\n",
    "        backend: statevector, qasm simulator or a real backend.\n",
    "        truncation: a threshold number to truncate the blocks. Default: None.\n",
    "    Returns:\n",
    "        qcc_circuit\n",
    "    '''\n",
    "    if truncation != None:\n",
    "        if len(entanglers) > truncation:\n",
    "            num_blocks = truncation\n",
    "        else:\n",
    "            num_blocks = len(entanglers)\n",
    "    else:\n",
    "        num_blocks = len(entanglers)\n",
    "    \n",
    "    # p = ParameterVector('p', num_blocks)\n",
    "    p = [0.0944527, 0.04799566, -0.0590973, -0.05908328, 0.04114604, 0.02695483, 0.02604318, 0.03485649]\n",
    "    \n",
    "    # num_qubits = len(entanglers[0])\n",
    "    qcc_circuit = QuantumCircuit(num_qubits)\n",
    "    for i in range(num_blocks):\n",
    "        circuit = QuantumCircuit(num_qubits)\n",
    "        key = entanglers[i]\n",
    "        coupler_map = []\n",
    "        # We first construct coupler_map according to the key.\n",
    "        for j in range(num_qubits):\n",
    "            if key[num_qubits-1-j] != 'I':\n",
    "                coupler_map.append(j)\n",
    "                \n",
    "        # Then we construct the circuit.\n",
    "        if len(coupler_map) == 1:\n",
    "            # there is no CNOT gate.\n",
    "            c = coupler_map[0]\n",
    "            if key[num_qubits-1-c] == 'X':\n",
    "                circuit.h(c)\n",
    "                circuit.rz(p[i], c)\n",
    "                circuit.h(c)\n",
    "            elif key[num_qubits-1-c] == 'Y':\n",
    "                circuit.rx(-np.pi/2, c)\n",
    "                circuit.rz(p[i], c)\n",
    "                circuit.rx(np.pi/2, c)\n",
    "                \n",
    "            qcc_circuit += circuit\n",
    "        else:\n",
    "            # Here we would need CNOT gate.\n",
    "            for j in coupler_map:\n",
    "                if key[num_qubits-1-j] == 'X':\n",
    "                    circuit.h(j)\n",
    "                elif key[num_qubits-1-j] == 'Y':\n",
    "                    circuit.rx(-np.pi/2, j)\n",
    "                    \n",
    "            for j in range(len(coupler_map) - 1):\n",
    "                circuit.cx(coupler_map[j], coupler_map[j+1])\n",
    "                \n",
    "            param_gate = QuantumCircuit(num_qubits)\n",
    "            param_gate.rz(p[i], coupler_map[-1])\n",
    "            \n",
    "            #qcc_circuit += circuit + param_gate + circuit.inverse()\n",
    "            qcc_circuit.compose(circuit, inplace=True)\n",
    "            qcc_circuit.compose(param_gate, inplace=True)\n",
    "            qcc_circuit.compose(circuit.inverse(), inplace=True)\n",
    "    \n",
    "    # Would the optimization level setting to 3 represent the best Qiksit optimization?\n",
    "    # trans_circuit = transpile(qcc_circuit, backend=backend, optimization_level=3)\n",
    "    \n",
    "    return qcc_circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62fc5724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the ansatz circuit\n",
    "\n",
    "# num_checks = 4\n",
    "# num_qubits = 4\n",
    "# total_qubits = num_checks + num_qubits\n",
    "# def hydrogen_trial_circuit(num_qubits):\n",
    "#     qc = QuantumCircuit(num_qubits)\n",
    "#     # prepare the Hartree-Fock state\n",
    "#     qc.x(0)\n",
    "#     qc.x(1)\n",
    "    \n",
    "#     qc.rx(np.pi/2, 0)\n",
    "#     qc.h(1)\n",
    "#     qc.h(2)\n",
    "#     qc.h(3)\n",
    "    \n",
    "#     qc.cx(0,1)\n",
    "#     qc.cx(1,2)\n",
    "#     qc.cx(2,3)\n",
    "    \n",
    "#     qc.rz(1.0, 3)\n",
    "    \n",
    "#     qc.cx(2,3)\n",
    "#     qc.cx(1,2)\n",
    "#     qc.cx(0,1)\n",
    "    \n",
    "#     qc.rx(-np.pi/2, 0)\n",
    "#     qc.h(1)\n",
    "#     qc.h(2)\n",
    "#     qc.h(3)\n",
    "    \n",
    "#     return qc\n",
    "\n",
    "# def generalized_trial_circuit(num_qubits, num_checks):\n",
    "#     total_qubits = num_qubits + num_checks\n",
    "#     qc = QuantumCircuit(total_qubits)\n",
    "#     # Hartree-Fock state preparation for an even number of qubits\n",
    "#     for i in range(num_qubits // 2):\n",
    "#         qc.x(i)\n",
    "    \n",
    "#     # Generalized entanglement pattern\n",
    "#     for i in range(num_qubits - 1):\n",
    "#         qc.h(i)\n",
    "#         qc.cx(i, i + 1)\n",
    "    \n",
    "#     qc.rz(1.0, num_qubits - 1)\n",
    "    \n",
    "#     for i in reversed(range(num_qubits - 1)):\n",
    "#         qc.cx(i, i + 1)\n",
    "#         qc.h(i)\n",
    "    \n",
    "#     return qc\n",
    "\n",
    "def hf_circ(num_qubits, num_checks):\n",
    "    total_qubits = num_qubits + num_checks\n",
    "    \n",
    "    hf_circuit = QuantumCircuit(total_qubits)\n",
    "    hf_circuit.x(0)\n",
    "    hf_circuit.x(3)\n",
    "        \n",
    "    entanglers = ['XXXXXY', 'XXXIYI', 'IXIXXY', 'IXIIYI', 'IXXIXY', 'XXIXYI', 'IIIXIY', 'XIYIII']\n",
    "\n",
    "    parameterized_circuit = hf_circuit.compose(construct_qcc_circuit(entanglers))\n",
    "    \n",
    "    return parameterized_circuit\n",
    "\n",
    "def hydrogen_shadow_circuit(Clifford, num_qubits):\n",
    "    # qc = hydrogen_trial_circuit(num_qubits)\n",
    "    # qc = generalized_trial_circuit(num_qubits, num_checks=0)\n",
    "    qc = hf_circ(num_qubits, num_checks=0)\n",
    "    \n",
    "    clifford_circuit = Clifford.to_circuit()\n",
    "    # qc.compose(clifford_circuit, qubits=[0,1,2,3], inplace=True)\n",
    "    qc.compose(clifford_circuit, qubits=range(num_qubits), inplace=True)\n",
    "    qc.measure_all()\n",
    "    return qc\n",
    "\n",
    "def hydrogen_shadow_PCS_circuit(Clifford, num_qubits, num_checks):\n",
    "    total_qubits = num_qubits + num_checks\n",
    "    # qc = hydrogen_trial_circuit(total_qubits)\n",
    "    # qc = generalized_trial_circuit(num_qubits, num_checks)\n",
    "    qc = hf_circ(num_qubits, num_checks)\n",
    "\n",
    "    clif_qc = Clifford.to_circuit()\n",
    "    \n",
    "    characters = ['I', 'Z']\n",
    "    strings = [''.join(p) for p in itertools.product(characters, repeat=num_qubits)]\n",
    "    \n",
    "    test_finder = ChecksFinder(num_qubits, clif_qc)\n",
    "    p1_list = []\n",
    "    for string in strings:\n",
    "        string_list = list(string)\n",
    "        result = test_finder.find_checks_sym(pauli_group_elem = string_list)\n",
    "        #print(result.p1_str, result.p2_str)\n",
    "        p1_list.append([result.p1_str, result.p2_str])\n",
    "        \n",
    "    sorted_list = sorted(p1_list, key=lambda s: s[1].count('I'))\n",
    "    pauli_list = sorted_list[-num_qubits -1:-1]\n",
    "    \n",
    "    #\n",
    "    initial_layout = {}\n",
    "    for i in range(0, num_qubits):\n",
    "        initial_layout[i] = [i]\n",
    "\n",
    "    final_layout = {}\n",
    "    for i in range(0, num_qubits):\n",
    "        final_layout[i] = [i]\n",
    "        \n",
    "    #add pauli check on two sides:\n",
    "    #specify the left and right pauli strings\n",
    "    pcs_qc_list = []\n",
    "    sign_list = []\n",
    "    pl_list = []\n",
    "    pr_list = []\n",
    "\n",
    "    for i in range(0, num_checks):\n",
    "        pl = pauli_list[i][0][2:]\n",
    "        pr = pauli_list[i][1][2:]\n",
    "        if i == 0:\n",
    "            temp_qc = add_pauli_checks(clif_qc, pl, pr, initial_layout, final_layout, False, False, False, False, False)\n",
    "            save_qc = add_pauli_checks(clif_qc, pl, pr, initial_layout, final_layout, False, False, False, False, False)\n",
    "            prev_qc = temp_qc\n",
    "        else:\n",
    "            temp_qc = add_pauli_checks(prev_qc, pl, pr, initial_layout, final_layout, False, False, False, False, False)\n",
    "            save_qc = add_pauli_checks(prev_qc, pl, pr, initial_layout, final_layout, False, False, False, False, False) \n",
    "            prev_qc = temp_qc\n",
    "        pl_list.append(pl)\n",
    "        pr_list.append(pr)\n",
    "        sign_list.append(pauli_list[i][0][:2])\n",
    "        pcs_qc_list.append(save_qc)\n",
    "\n",
    "    qc.barrier()\n",
    "    qc.compose(pcs_qc_list[-1], qubits=[i for i in range(0, total_qubits)], inplace=True)\n",
    "    qc.barrier()\n",
    "    \n",
    "    qc.measure_all()\n",
    "    return sign_list, qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6812f9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 9999\n",
      "2 9999\n"
     ]
    }
   ],
   "source": [
    "num_qubits = 6\n",
    "num_checks = 4\n",
    "C_list = []\n",
    "for i in range(total_trials):\n",
    "    # Clifford = random_clifford(4)\n",
    "    Clifford = random_clifford(num_qubits)\n",
    "    C_list.append(Clifford)\n",
    "circs_list = []\n",
    "signs_list = []\n",
    "for check_id in range(1, num_checks + 1):\n",
    "    print(check_id, i)\n",
    "    circs = []\n",
    "    signs = []\n",
    "    for i in range(total_trials):\n",
    "        sign, circuit = hydrogen_shadow_PCS_circuit(C_list[i], num_qubits, check_id)\n",
    "        signs.append(sign)\n",
    "        circs.append(circuit)\n",
    "    circs_list.append(circs)\n",
    "    signs_list.append(signs)\n",
    "    \n",
    "orign_circs = []\n",
    "for i in range(total_trials):\n",
    "    circuit = hydrogen_shadow_circuit(C_list[i], num_qubits)\n",
    "    orign_circs.append(circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e18609",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(orign_circs))\n",
    "print(orign_circs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505aa044",
   "metadata": {},
   "outputs": [],
   "source": [
    "circs_list[0][-1].draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b320da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_results_reindex(dictionary, qubits, indexes, sign_list):\n",
    "    new_dict = {}\n",
    "    for key in dictionary.keys():\n",
    "        new_key = ''\n",
    "        for i in range(len(key)):\n",
    "            meas_index = i\n",
    "#             if i < len(sign_list):\n",
    "#                 print(key, \"index\", i, key[i], sign_list[meas_index])\n",
    "            if meas_index in indexes and key[i] == sign_list[meas_index]:\n",
    "                #the key equals the sign, keep\n",
    "                new_key = ''\n",
    "                break\n",
    "            if meas_index not in indexes:\n",
    "                new_key += key[i]\n",
    "        if new_key != '':\n",
    "            new_dict[new_key] = dictionary[key]\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b13dc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661f3b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_lists_filtered = []\n",
    "check_id = 1\n",
    "# Submit hardware jobs via Qiskit Runtime;\n",
    "\n",
    "with Session(backend=backend) as session:\n",
    "    sampler = Sampler(session=session, options=options)\n",
    "\n",
    "    # same as the calibration process\n",
    "    job = sampler.run(circs_list[check_id-1], shots=1024, initial_layout=[])\n",
    "    print(f\"Job ID: {job.job_id()}\")\n",
    "    print(f\">>> Job Status: {job.status()}\")\n",
    "\n",
    "    result = job.result()\n",
    "\n",
    "    # Close the session only if all jobs are finished\n",
    "    # and you don't need to run more in the session.\n",
    "    session.close()\n",
    "\n",
    "b_lists_check = []\n",
    "\n",
    "for i in range(total_trials):\n",
    "    di = {}\n",
    "    for key in list(result.quasi_dists[i].binary_probabilities().keys()):\n",
    "        di.update({key[:num_qubits + check_id]: result.quasi_dists[i].binary_probabilities().get(key)})\n",
    "    b_lists_check.append(di)\n",
    "\n",
    "\n",
    "filtered_b_lists = []\n",
    "for i in range(total_trials):\n",
    "    bit_list = ['1' if i == '+1' else '0' for i in signs_list[check_id-1][i][check_id - 1::-1]]\n",
    "#     print(bit_list)\n",
    "    filted_dist = filter_results_reindex(b_lists_check[i], num_qubits, [j for j in range(0, check_id)], bit_list)\n",
    "    print(total_counts(filted_dist))\n",
    "    filtered_b_lists.append(filted_dist)\n",
    "b_lists_filtered.append(filtered_b_lists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0db8d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_id = 2\n",
    "# Submit hardware jobs via Qiskit Runtime;\n",
    "\n",
    "with Session(backend=backend) as session:\n",
    "    sampler = Sampler(session=session, options=options)\n",
    "\n",
    "    # same as the calibration process\n",
    "    job = sampler.run(circs_list[check_id-1], shots=1024, initial_layout=[])\n",
    "    print(f\"Job ID: {job.job_id()}\")\n",
    "    print(f\">>> Job Status: {job.status()}\")\n",
    "\n",
    "    result = job.result()\n",
    "\n",
    "    # Close the session only if all jobs are finished\n",
    "    # and you don't need to run more in the session.\n",
    "    session.close()\n",
    "\n",
    "b_lists_check = []\n",
    "\n",
    "for i in range(total_trials):\n",
    "    di = {}\n",
    "    for key in list(result.quasi_dists[i].binary_probabilities().keys()):\n",
    "        di.update({key[:num_qubits + check_id]: result.quasi_dists[i].binary_probabilities().get(key)})\n",
    "    b_lists_check.append(di)\n",
    "\n",
    "\n",
    "filtered_b_lists = []\n",
    "for i in range(total_trials):\n",
    "    bit_list = ['1' if i == '+1' else '0' for i in signs_list[check_id-1][i][check_id - 1::-1]]\n",
    "#     print(bit_list)\n",
    "    filted_dist = filter_results_reindex(b_lists_check[i], num_qubits, [j for j in range(0, check_id)], bit_list)\n",
    "    print(total_counts(filted_dist))\n",
    "    filtered_b_lists.append(filted_dist)\n",
    "b_lists_filtered.append(filtered_b_lists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ffdb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "check_id = 3\n",
    "# Submit hardware jobs via Qiskit Runtime;\n",
    "\n",
    "with Session(backend=backend) as session:\n",
    "    sampler = Sampler(session=session, options=options)\n",
    "\n",
    "    # same as the calibration process\n",
    "    job = sampler.run(circs_list[check_id-1], shots=1024, initial_layout=[])\n",
    "    print(f\"Job ID: {job.job_id()}\")\n",
    "    print(f\">>> Job Status: {job.status()}\")\n",
    "\n",
    "    result = job.result()\n",
    "\n",
    "    # Close the session only if all jobs are finished\n",
    "    # and you don't need to run more in the session.\n",
    "    session.close()\n",
    "\n",
    "b_lists_check = []\n",
    "\n",
    "for i in range(total_trials):\n",
    "    di = {}\n",
    "    for key in list(result.quasi_dists[i].binary_probabilities().keys()):\n",
    "        di.update({key[:num_qubits + check_id]: result.quasi_dists[i].binary_probabilities().get(key)})\n",
    "    b_lists_check.append(di)\n",
    "\n",
    "\n",
    "filtered_b_lists = []\n",
    "for i in range(total_trials):\n",
    "    bit_list = ['1' if i == '+1' else '0' for i in signs_list[check_id-1][i][check_id - 1::-1]]\n",
    "#     print(bit_list)\n",
    "    filted_dist = filter_results_reindex(b_lists_check[i], num_qubits, [j for j in range(0, check_id)], bit_list)\n",
    "    print(total_counts(filted_dist))\n",
    "    filtered_b_lists.append(filted_dist)\n",
    "b_lists_filtered.append(filtered_b_lists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c520de0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "check_id = 4\n",
    "# Submit hardware jobs via Qiskit Runtime;\n",
    "\n",
    "with Session(backend=backend) as session:\n",
    "    sampler = Sampler(session=session, options=options)\n",
    "\n",
    "    # same as the calibration process\n",
    "    job = sampler.run(circs_list[check_id-1], shots=1024, initial_layout=[])\n",
    "    print(f\"Job ID: {job.job_id()}\")\n",
    "    print(f\">>> Job Status: {job.status()}\")\n",
    "\n",
    "    result = job.result()\n",
    "\n",
    "    # Close the session only if all jobs are finished\n",
    "    # and you don't need to run more in the session.\n",
    "    session.close()\n",
    "\n",
    "b_lists_check = []\n",
    "\n",
    "for i in range(total_trials):\n",
    "    di = {}\n",
    "    for key in list(result.quasi_dists[i].binary_probabilities().keys()):\n",
    "        di.update({key[:num_qubits + check_id]: result.quasi_dists[i].binary_probabilities().get(key)})\n",
    "    b_lists_check.append(di)\n",
    "\n",
    "\n",
    "filtered_b_lists = []\n",
    "for i in range(total_trials):\n",
    "    bit_list = ['1' if i == '+1' else '0' for i in signs_list[check_id-1][i][check_id - 1::-1]]\n",
    "#     print(bit_list)\n",
    "    filted_dist = filter_results_reindex(b_lists_check[i], num_qubits, [j for j in range(0, check_id)], bit_list)\n",
    "    print(total_counts(filted_dist))\n",
    "    filtered_b_lists.append(filted_dist)\n",
    "b_lists_filtered.append(filtered_b_lists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e2dd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit hardware jobs via Qiskit Runtime;\n",
    "\n",
    "with Session(backend=backend) as session:\n",
    "    sampler = Sampler(session=session, options=options)\n",
    "    \n",
    "    # same as the calibration process\n",
    "    job = sampler.run(orign_circs, shots=1024, initial_layout=[i for i in range(0, num_qubits)])\n",
    "    print(f\"Job ID: {job.job_id()}\")\n",
    "    print(f\">>> Job Status: {job.status()}\")\n",
    "    \n",
    "    result = job.result()\n",
    "    \n",
    "    # Close the session only if all jobs are finished\n",
    "    # and you don't need to run more in the session.\n",
    "    session.close()\n",
    "    \n",
    "b_lists = []\n",
    "\n",
    "for i in range(total_trials):\n",
    "    di = {}\n",
    "    for key in list(result.quasi_dists[i].binary_probabilities().keys()):\n",
    "        di.update({key[:num_qubits + num_checks]: result.quasi_dists[i].binary_probabilities().get(key)})\n",
    "    b_lists.append(di)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be267d6",
   "metadata": {},
   "source": [
    "Noiseless Experiments on qiskitruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0657001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_ibm_runtime import QiskitRuntimeService, Session, Sampler, Options\n",
    "\n",
    "options = Options(optimization_level=2, resilience_level=1)\n",
    "# backend = service.get_backend(\"ibmq_qasm_simulator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ee4606",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Session(backend=backend) as session:\n",
    "    sampler = Sampler(session=session, options=options)\n",
    "\n",
    "    job = sampler.run(orign_circs, shots=1024)\n",
    "    print(f\"Job ID: {job.job_id()}\")\n",
    "    print(f\">>> Job Status: {job.status()}\")\n",
    "    \n",
    "    result = job.result()\n",
    "    \n",
    "    # Close the session only if all jobs are finished\n",
    "    # and you don't need to run more in the session.\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d4bd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def filter_results(dictionary, qubits, indexes, sign_list):\n",
    "    new_dict = {}\n",
    "    for key in dictionary.keys():\n",
    "        new_key = ''\n",
    "        for i in range(len(key)):\n",
    "            meas_index = i\n",
    "            #print(key, meas_index, indexes)\n",
    "            if meas_index in indexes and key[i] == sign_list[meas_index]:\n",
    "                new_key = ''\n",
    "                break\n",
    "            if meas_index not in indexes:\n",
    "                new_key += key[i]\n",
    "        if new_key != '':\n",
    "            new_dict[new_key] = dictionary[key]\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046abcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_lists_noiseless = []\n",
    "\n",
    "for i in range(total_trials):\n",
    "    di = {}\n",
    "    for key in list(result.quasi_dists[i].binary_probabilities().keys()):\n",
    "        di.update({key[:num_qubits]: result.quasi_dists[i].binary_probabilities().get(key)})\n",
    "    b_lists_noiseless.append(di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dd498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_expectation(b_lists, b_lists_checks, b_lists_noiseless, C_list, operator_list, num_qubits, f_tilde):\n",
    "    \"\"\"\n",
    "    Reconstruct a state approximation as an average over all snapshots in the shadow.\n",
    "    Args:\n",
    "        shadow (tuple): A shadow tuple obtained from `calculate_classical_shadow`.\n",
    "        operator (np.ndarray):\n",
    "        num_qubits\n",
    "    Returns:\n",
    "        Numpy array with the reconstructed quantum state.\n",
    "    \"\"\"\n",
    "    num_snapshots = len(b_lists)\n",
    "    \n",
    "    # Averaging over snapshot states.\n",
    "    expectation_list = np.zeros(len(operator_list))\n",
    "    expectation_list_r = np.zeros(len(operator_list))\n",
    "    expectation_list_checks = [np.zeros(len(operator_list)) for i in range(len(b_lists_checks))]\n",
    "    expectation_list_noiseless = np.zeros(len(operator_list))\n",
    "    \n",
    "    for i in range(num_snapshots):\n",
    "        noisy, robust = expectation_snapshot(b_lists[i], C_list[i], operator_list, num_qubits, f_tilde)\n",
    "        expectation_list += noisy\n",
    "        expectation_list_r += robust\n",
    "        \n",
    "        for j in range(len(b_lists_checks)):\n",
    "            check = expectation_snapshot_noiseless(b_lists_checks[j][i], C_list[i], operator_list, num_qubits)\n",
    "            expectation_list_checks[j] += check \n",
    "            \n",
    "        \n",
    "        noiseless = expectation_snapshot_noiseless(b_lists_noiseless[i], C_list[i], operator_list, num_qubits)\n",
    "        expectation_list_noiseless += noiseless\n",
    "        \n",
    "    expectation_list /= num_snapshots\n",
    "    expectation_list_r /= num_snapshots\n",
    "    for j in range(len(b_lists_checks)):\n",
    "        expectation_list_checks[j] /= num_snapshots\n",
    "    expectation_list_noiseless /= num_snapshots\n",
    "    \n",
    "    return expectation_list, expectation_list_r, expectation_list_checks, expectation_list_noiseless\n",
    "\n",
    "\n",
    "def expectation_snapshot(b_dict, clifford, operator_list, num_qubits, f_tilde):\n",
    "    \"\"\"\n",
    "    Helper function for `shadow_state_reconstruction` that reconstructs the overlap estimate from\n",
    "    a single snapshot in a shadow. Implements Eq. (S23) from https://arxiv.org/pdf/2106.16235.pdf\n",
    "    Args:\n",
    "        b_dict (dict): The list of classical outcomes for the snapshot.\n",
    "        clifford: Indices for the applied Pauli measurement.\n",
    "        operator:\n",
    "        num_qubits:\n",
    "    Returns:\n",
    "        Numpy array with the reconstructed snapshot.\n",
    "    \"\"\"\n",
    "    f = 1/(2**num_qubits+1)\n",
    "    # reconstructing the snapshot state from random Clifford measurements\n",
    "    U = clifford.to_matrix()\n",
    "    I = np.eye(2**num_qubits)\n",
    "    \n",
    "    # applying Eq. (S32), note that this expression is built upon random Clifford, so that inverting\n",
    "    # the quantum channel follows Eq. (S29).\n",
    "    snapshot_list = np.zeros(len(operator_list))\n",
    "    snapshot_list_r = np.zeros(len(operator_list))\n",
    "    denom = 0\n",
    "    for b_state in list(b_dict.keys()):\n",
    "        matrix_part = U.conj().T @ state_reconstruction(b_state) @ U\n",
    "        \n",
    "        interm = 1 / f * matrix_part\n",
    "        interm -= (1 / f - 1)/2**num_qubits * I\n",
    "        \n",
    "        interm_r = 1 / f_tilde * matrix_part\n",
    "        interm_r -= (1 / f_tilde - 1) / 2**num_qubits * I\n",
    "        \n",
    "        for index, operator in enumerate(operator_list):\n",
    "            operator_matrix = operator.to_matrix()\n",
    "            snapshot_list[index] += np.real(np.trace(operator_matrix @ interm) * b_dict.get(b_state))\n",
    "            snapshot_list_r[index] += np.real(np.trace(operator_matrix @ interm_r) * b_dict.get(b_state))\n",
    "            \n",
    "        denom += b_dict.get(b_state)\n",
    "    \n",
    "    return snapshot_list / denom, snapshot_list_r / denom\n",
    "\n",
    "\n",
    "def expectation_snapshot_noiseless(b_dict, clifford, operator_list, num_qubits):\n",
    "    \"\"\"\n",
    "    Helper function for `shadow_state_reconstruction` that reconstructs the overlap estimate from\n",
    "    a single snapshot in a shadow. Implements Eq. (S23) from https://arxiv.org/pdf/2106.16235.pdf\n",
    "    Args:\n",
    "        b_dict (dict): The list of classical outcomes for the snapshot.\n",
    "        clifford: Indices for the applied Pauli measurement.\n",
    "        operator:\n",
    "        num_qubits:\n",
    "    Returns:\n",
    "        Numpy array with the reconstructed snapshot.\n",
    "    \"\"\"\n",
    "    f = 1/(2**num_qubits+1)\n",
    "    # reconstructing the snapshot state from random Clifford measurements\n",
    "    U = clifford.to_matrix()\n",
    "    I = np.eye(2**num_qubits)\n",
    "    \n",
    "    # applying Eq. (S32), note that this expression is built upon random Clifford, so that inverting\n",
    "    # the quantum channel follows Eq. (S29).\n",
    "    snapshot_list = np.zeros(len(operator_list))\n",
    "    denom = 0\n",
    "    for b_state in list(b_dict.keys()):\n",
    "        interm = 1/f * U.conj().T @ state_reconstruction(b_state) @ U\n",
    "        interm -= (1/f - 1)/2**num_qubits * I\n",
    "        \n",
    "        for index, operator in enumerate(operator_list):\n",
    "            operator_matrix = operator.to_matrix()\n",
    "            snapshot_list[index] += np.real(np.trace(operator_matrix @ interm) * b_dict.get(b_state))\n",
    "            \n",
    "        denom += b_dict.get(b_state)\n",
    "    \n",
    "    return snapshot_list / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e36bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the classical shadows postprocessing to get expectation values;\n",
    "\n",
    "Paulis = ['XXXXXX', 'YYYYYY', 'XYXYXY', 'YXYXYX', 'YYYXXX', 'XXXYYY', 'ZZZZZZ', 'ZZIIII', 'IIZZII', 'IIIIZZ',\n",
    "         'XZXZXZ', 'ZXZXZX', 'ZZZXXX', 'XXXZZZ', 'IIIIXX', 'XXIIII', 'XXIIXX']\n",
    "\n",
    "operator_list = []\n",
    "for pauli in Paulis:\n",
    "    operator_list.append(Pauli(pauli))\n",
    "\n",
    "# psi = Statevector(hydrogen_trial_circuit(num_qubits))\n",
    "# psi = Statevector(generalized_trial_circuit(num_qubits, num_checks=0))\n",
    "psi = Statevector(hf_circ(num_qubits, num_checks=0))\n",
    "ref_list = []\n",
    "for operator in operator_list:\n",
    "    expect = np.array(psi).T.conj() @ operator.to_matrix() @ np.array(psi)\n",
    "    ref_list.append(expect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9428119",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_runs = 20\n",
    "shadow_range = [100, 400, 1000, 4000, 10000]\n",
    "num_of_checks = 4\n",
    "\n",
    "expectation_shadow = np.zeros((len(shadow_range), len(Paulis), num_of_runs))\n",
    "expectation_shadow_r = np.zeros((len(shadow_range), len(Paulis), num_of_runs))\n",
    "expectation_shadow_check1 = np.zeros((len(shadow_range), len(Paulis), num_of_runs))\n",
    "expectation_shadow_check2 = np.zeros((len(shadow_range), len(Paulis), num_of_runs))\n",
    "expectation_shadow_check3 = np.zeros((len(shadow_range), len(Paulis), num_of_runs))\n",
    "expectation_shadow_check4 = np.zeros((len(shadow_range), len(Paulis), num_of_runs))\n",
    "expectation_shadow_noiseless = np.zeros((len(shadow_range), len(Paulis), num_of_runs))\n",
    "\n",
    "for j, num_snapshots in enumerate(shadow_range):\n",
    "    print('num snapshots = ', num_snapshots)\n",
    "    indices = random.sample(range(total_trials), num_snapshots)\n",
    "\n",
    "    # Partition indices into 'num_of_runs' equally sized chunks\n",
    "    partitions = np.array_split(indices, num_of_runs)\n",
    "        \n",
    "    for i, run_indices in enumerate(partitions):\n",
    "        C_sublist = [C_list[k] for k in run_indices]\n",
    "        b_sublists = [b_lists[k] for k in run_indices]\n",
    "        b_sublists_check1 = [b_lists_filtered[0][k] for k in run_indices]\n",
    "        b_sublists_check2 = [b_lists_filtered[1][k] for k in run_indices]\n",
    "        b_sublists_check3 = [b_lists_filtered[2][k] for k in run_indices]\n",
    "        b_sublists_check4 = [b_lists_filtered[3][k] for k in run_indices]\n",
    "        b_sublists_checks = [b_sublists_check1,b_sublists_check2, b_sublists_check3, b_sublists_check4]\n",
    "        b_sublists_noiseless = [b_lists_noiseless[k] for k in run_indices]\n",
    "\n",
    "        expectation_list, expectation_list_r, expectation_list_checks, expectation_list_noiseless = compute_expectation(\n",
    "            b_sublists, b_sublists_checks,  b_sublists_noiseless, C_sublist, operator_list, num_qubits, f_tilde\n",
    "        )\n",
    "\n",
    "        expectation_shadow[j, :, i] = np.real(expectation_list)\n",
    "        expectation_shadow_r[j, :, i] = np.real(expectation_list_r)\n",
    "        expectation_shadow_check1[j, :, i] = np.real(expectation_list_checks[0])\n",
    "        expectation_shadow_check2[j, :, i] = np.real(expectation_list_checks[1])\n",
    "        expectation_shadow_check3[j, :, i] = np.real(expectation_list_checks[2])\n",
    "        expectation_shadow_check4[j, :, i] = np.real(expectation_list_checks[3])\n",
    "        expectation_shadow_noiseless[j, :, i] = np.real(expectation_list_noiseless)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435e9a59",
   "metadata": {},
   "source": [
    "#### Extrapolation of expectation example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4286289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from numpy.polynomial.polynomial import Polynomial\n",
    "\n",
    "# medians = [np.median(check, axis=2) for check in [expectation_shadow_check1, expectation_shadow_check2, expectation_shadow_check3]]#, expectation_shadow_check4]]\n",
    "\n",
    "# shadow_size_index = -1  # largest shadow size\n",
    "# pauli_index = 1  # Example observable index\n",
    "# expectation_values = [median[shadow_size_index, pauli_index] for median in medians]\n",
    "\n",
    "# # Fit a Straight Line\n",
    "# check_numbers = [1, 2, 3]  # Numeric x-values for fitting\n",
    "# polynomial = Polynomial.fit(check_numbers, expectation_values, 1)\n",
    "\n",
    "# # Extrapolate to the Fifth Layer\n",
    "# extrapolated_check = 6\n",
    "# extrapolated_value = polynomial(extrapolated_check)\n",
    "\n",
    "# # Plotting\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(check_numbers, expectation_values, color='blue', label='Measured Data')\n",
    "# plt.plot(np.linspace(1, 5, 400), polynomial(np.linspace(1, 5, 400)), color='red', label='Fitted Line')\n",
    "# plt.scatter([extrapolated_check], [extrapolated_value], color='green', label='Extrapolated for 5th Layer')\n",
    "\n",
    "# plt.xlabel('Number of Check Layers')\n",
    "# plt.ylabel(f'Median Expectation Value for {shadow_range[shadow_size_index]} snapshots')\n",
    "# plt.title(f'Extrapolation of Expectation Value for Oberservable {Paulis[pauli_index]}')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56798df",
   "metadata": {},
   "source": [
    "#### Calculate extrapolated checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8f05d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.polynomial.polynomial import Polynomial\n",
    "\n",
    "medians = [np.median(check, axis=2) for check in [expectation_shadow_check1, expectation_shadow_check2, expectation_shadow_check3, expectation_shadow_check4]]\n",
    "check_numbers = [1, 2, 3, 4]  # Original check layers\n",
    "extrapolation_layers = [6]  \n",
    "\n",
    "# Initialize a three-dimensional array to store extrapolated values\n",
    "# Dimensions: [extrapolated layer (4-8), shadow size, Paulis]\n",
    "expectation_check_limit = np.zeros((len(extrapolation_layers), len(shadow_range), len(Paulis)))\n",
    "\n",
    "for layer_index, layer in enumerate(extrapolation_layers):\n",
    "    for shadow_size_index in range(len(medians[0])):\n",
    "        for pauli_index in range(medians[0].shape[1]):\n",
    "            expectation_values = [median[shadow_size_index, pauli_index] for median in medians]\n",
    "            polynomial = Polynomial.fit(check_numbers, expectation_values, 1)\n",
    "            # Extrapolate the value for the current layer\n",
    "            extrapolated_value = polynomial(layer)\n",
    "            expectation_check_limit[layer_index, shadow_size_index, pauli_index] = extrapolated_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621dd96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(expectation_check_limit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8527dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "error = np.zeros(len(shadow_range))\n",
    "error_r = np.zeros(len(shadow_range))\n",
    "error_check1 = np.zeros(len(shadow_range))\n",
    "error_check2 = np.zeros(len(shadow_range))\n",
    "error_check3 = np.zeros(len(shadow_range))\n",
    "error_check4 = np.zeros(len(shadow_range))\n",
    "print(error_check4.shape)\n",
    "print(expectation_shadow_check4.shape)\n",
    "error_noiseless = np.zeros(len(shadow_range))\n",
    "\n",
    "for i in range(len(shadow_range)):\n",
    "    error[i] = np.mean([np.abs(np.median(expectation_shadow[i], axis=1)[j] - ref_list[j]) for j in range(len(ref_list))])\n",
    "    error_r[i] = np.mean([np.abs(np.median(expectation_shadow_r[i], axis=1)[j] - ref_list[j]) for j in range(len(ref_list))])\n",
    "    error_check1[i] = np.mean([np.abs(np.median(expectation_shadow_check1[i], axis=1)[j] - ref_list[j]) for j in range(len(ref_list))])\n",
    "    error_check2[i] = np.mean([np.abs(np.median(expectation_shadow_check2[i], axis=1)[j] - ref_list[j]) for j in range(len(ref_list))])\n",
    "    error_check3[i] = np.mean([np.abs(np.median(expectation_shadow_check3[i], axis=1)[j] - ref_list[j]) for j in range(len(ref_list))])\n",
    "    error_check4[i] = np.mean([np.abs(np.median(expectation_shadow_check4[i], axis=1)[j] - ref_list[j]) for j in range(len(ref_list))])\n",
    "    error_noiseless[i] = np.mean([np.abs(np.median(expectation_shadow_noiseless[i], axis=1)[j] - ref_list[j]) for j in range(len(ref_list))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3716fea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_check_limit = np.zeros((len(extrapolation_layers), len(shadow_range)))\n",
    "\n",
    "for layer_index, layer in enumerate(extrapolation_layers):\n",
    "    for shadow_size_index in range(len(shadow_range)):\n",
    "        # Calculate the mean error for this layer and shadow size across all Pauli indices\n",
    "        error_check_limit[layer_index, shadow_size_index] = np.mean(\n",
    "            [np.abs(expectation_check_limit[layer_index, shadow_size_index, pauli_index] - ref_list[pauli_index]) for pauli_index in range(len(Paulis))]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86fb167",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(error_check_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52160d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 4), dpi=100)\n",
    "plt.plot(shadow_range, error, '--o', ms=8, color='tab:orange', label='noisy')\n",
    "plt.plot(shadow_range, error_check1, '--o', ms=8, color='tab:red', label='check1')\n",
    "plt.plot(shadow_range, error_check2, '--o', ms=8, color='tab:purple', label='check2')\n",
    "plt.plot(shadow_range, error_check3, '--o', ms=8, color='tab:olive', label='check3')\n",
    "# plt.plot(shadow_range, error_check4, '--o', ms=8, color='tab:pink', label='check4')\n",
    "plt.plot(shadow_range, error_r, '--^', ms=8, color='tab:green', label='robust')\n",
    "plt.plot(shadow_range, error_noiseless, '--x', ms=8, color='tab:blue', label='noiseless')\n",
    "\n",
    "# Plotting each layer of extrapolated checks\n",
    "colors = ['tab:brown', 'tab:gray', 'tab:cyan', 'tab:pink', 'tab:purple'] \n",
    "for layer_index, layer in enumerate(extrapolation_layers):\n",
    "    plt.plot(shadow_range, error_check_limit[layer_index, :],  '--o', ms=8, label=f'check {layer} (extrap)')\n",
    "\n",
    "# Adjust the legend to be outside without altering the figure size\n",
    "plt.legend(fontsize=10, loc='upper left', bbox_to_anchor=(1.05, 1))\n",
    "plt.xlabel('Shadow size', fontsize=14)\n",
    "plt.ylabel('Error', fontsize=14)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.tick_params(labelsize=14)\n",
    "\n",
    "# Note: The figure's layout isn't altered with plt.tight_layout() in this case\n",
    "# Saving the figure with bbox_inches='tight' includes the external legend\n",
    "plt.savefig('non_idealchecks.png', dpi=100, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9bd923",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 4), dpi=100)\n",
    "plt.plot(shadow_range, error, '--o', ms=8, color='tab:blue', label='Robust Shadow')\n",
    "plt.legend(fontsize=14, loc='best')\n",
    "plt.xlabel('Shadow size', fontsize=14)\n",
    "plt.ylabel('Error', fontsize=14)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.tick_params(labelsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce02c636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db4cb4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pcs_test]",
   "language": "python",
   "name": "conda-env-pcs_test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
