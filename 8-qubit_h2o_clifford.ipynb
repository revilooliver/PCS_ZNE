{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c54421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, random\n",
    "import numpy as np\n",
    "# import pennylane as qml\n",
    "# from qiskit import Aer, transpile, execute\n",
    "from qiskit.circuit import QuantumCircuit\n",
    "from qiskit.quantum_info import random_clifford, Pauli, Statevector\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(precision=6, edgeitems=10, linewidth=150, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc907b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiskit\n",
    "import itertools\n",
    "from qiskit import *\n",
    "from qiskit.quantum_info import Clifford, random_clifford\n",
    "from qiskit.synthesis import synth_clifford_full\n",
    "from qiskit.quantum_info import hellinger_fidelity as hf\n",
    "\n",
    "from utils.pauli_checks import ChecksFinder, add_pauli_checks, add_meas_pauli_checks, add_linear_meas_pauli_checks,  search_for_pauli_list\n",
    "from utils.pauli_checks import gen_initial_layout, gen_final_layout, complete_postprocess, filter_results\n",
    "\n",
    "from utils.utils import norm_dict, total_counts\n",
    "# from utils.vqe_utils import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb83096-2815-4a14-b608-56f6b756cbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(qiskit.version.get_version_info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76c9417",
   "metadata": {},
   "source": [
    "#### I. Calibrating $\\tilde{f}$ in the noisy Clifford channel using hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6026e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trials = 10000\n",
    "num_qubits = 8\n",
    "def calibration_circuit(Clifford):\n",
    "    qc = QuantumCircuit(num_qubits)\n",
    "    \n",
    "    clifford_circuit = Clifford.to_circuit()\n",
    "    # qc.compose(clifford_circuit, qubits=[0,1,2,3], inplace=True)\n",
    "    qc.compose(clifford_circuit, qubits=range(num_qubits), inplace=True)\n",
    "    \n",
    "    qc.measure_all()\n",
    "    return qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a3e41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cali_C_list = []\n",
    "for i in range(total_trials):\n",
    "    # Clifford = random_clifford(4)\n",
    "    Clifford = random_clifford(num_qubits)\n",
    "    cali_C_list.append(Clifford)\n",
    "    \n",
    "cali_circs = []\n",
    "for i in range(total_trials):\n",
    "    circuit = calibration_circuit(cali_C_list[i])\n",
    "    cali_circs.append(circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ea06fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cali_circs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c80a9a",
   "metadata": {},
   "source": [
    "Set noise model and topolgoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "118055dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for SamplerOptions\nbackend_options\n  Unexpected keyword argument [type=unexpected_keyword_argument, input_value={'noise_model': <NoiseMod...'u1', 'x', 'sx', 'cx']>}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/unexpected_keyword_argument",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m noise_model\u001b[38;5;241m.\u001b[39madd_all_qubit_quantum_error(error_1, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mu1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mu2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mu3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     20\u001b[0m noise_model\u001b[38;5;241m.\u001b[39madd_all_qubit_quantum_error(error_2, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcx\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 22\u001b[0m noisy_sampler \u001b[38;5;241m=\u001b[39m \u001b[43mSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbackend_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnoise_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnoise_model\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# options = Options(optimization_level=2, resilience_level=1) # choose the proper levels on hardware\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# options.simulator = {\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#     \"noise_model\": noise_model,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# backend = service.get_backend(\"\") \u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# backend = \"ibmq_qasm_simulator\" # use the simulator for now\u001b[39;00m\n\u001b[1;32m     37\u001b[0m backend \u001b[38;5;241m=\u001b[39m AerSimulator()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pcs_test/lib/python3.10/site-packages/qiskit_ibm_runtime/sampler.py:92\u001b[0m, in \u001b[0;36mSamplerV2.__init__\u001b[0;34m(self, backend, session, options)\u001b[0m\n\u001b[1;32m     90\u001b[0m BaseSamplerV2\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m     91\u001b[0m Sampler\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m---> 92\u001b[0m \u001b[43mBasePrimitiveV2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pcs_test/lib/python3.10/site-packages/qiskit_ibm_runtime/base_primitive.py:89\u001b[0m, in \u001b[0;36mBasePrimitiveV2.__init__\u001b[0;34m(self, backend, session, options)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_service: QiskitRuntimeService \u001b[38;5;241m|\u001b[39m QiskitRuntimeLocalService \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend: Optional[BackendV1 \u001b[38;5;241m|\u001b[39m BackendV2] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(session, Session):\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session \u001b[38;5;241m=\u001b[39m session\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pcs_test/lib/python3.10/site-packages/qiskit_ibm_runtime/base_primitive.py:211\u001b[0m, in \u001b[0;36mBasePrimitiveV2._set_options\u001b[0;34m(self, options)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(options, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    210\u001b[0m     default_options \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options_class()\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_options_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmerge_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdefault_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(options, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options_class):\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options \u001b[38;5;241m=\u001b[39m replace(options)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pcs_test/lib/python3.10/site-packages/pydantic/_internal/_dataclasses.py:141\u001b[0m, in \u001b[0;36mcomplete_dataclass.<locals>.__init__\u001b[0;34m(__dataclass_self__, *args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    140\u001b[0m s \u001b[38;5;241m=\u001b[39m __dataclass_self__\n\u001b[0;32m--> 141\u001b[0m \u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mArgsKwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for SamplerOptions\nbackend_options\n  Unexpected keyword argument [type=unexpected_keyword_argument, input_value={'noise_model': <NoiseMod...'u1', 'x', 'sx', 'cx']>}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/unexpected_keyword_argument"
     ]
    }
   ],
   "source": [
    "# from qiskit_ibm_runtime import Session, Options, SamplerV2 as Sampler\n",
    "from qiskit_ibm_runtime import Session, Sampler, Options\n",
    "from qiskit_ibm_runtime.fake_provider import *\n",
    "from qiskit_aer import AerSimulator\n",
    "import qiskit_aer.noise as noise\n",
    "from itertools import combinations\n",
    "\n",
    "# Make a noise model\n",
    "fake_backend = FakeCairo()\n",
    "# noise_model = noise.NoiseModel.from_backend(fake_backend)\n",
    "\n",
    "prob_1 = 0.002  # 1-qubit gate\n",
    "prob_2 = 0.02   # 2-qubit gate\n",
    "\n",
    "error_1 = noise.depolarizing_error(prob_1, 1)\n",
    "error_2 = noise.depolarizing_error(prob_2, 2)\n",
    "\n",
    "noise_model = noise.NoiseModel()\n",
    "noise_model.add_all_qubit_quantum_error(error_1, ['u1', 'u2', 'u3', 'sx', 'x'])\n",
    "noise_model.add_all_qubit_quantum_error(error_2, ['cx'])\n",
    "\n",
    "options = Options(optimization_level=2, resilience_level=1) # choose the proper levels on hardware\n",
    "options.simulator = {\n",
    "    \"noise_model\": noise_model,\n",
    "    \"basis_gates\": fake_backend.configuration().basis_gates,\n",
    "    # \"coupling_map\": fake_backend.configuration().coupling_map,\n",
    "    \"seed_simulator\": 42\n",
    "}\n",
    "\n",
    "# backend = service.get_backend(\"\") \n",
    "# backend = \"ibmq_qasm_simulator\" # use the simulator for now\n",
    "backend = AerSimulator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf91f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(noise_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b29169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Session(backend=backend) as session:\n",
    "    sampler = Sampler(session=session, options=options)\n",
    "\n",
    "    # define physical qubits to be used in the layout arguement\n",
    "    job = sampler.run(cali_circs, shots=100)\n",
    "    print(f\"Job ID: {job.job_id()}\")\n",
    "    print(f\">>> Job Status: {job.status()}\")\n",
    "\n",
    "    result = job.result()\n",
    "\n",
    "    # Close the session only if all jobs are finished\n",
    "    # and you don't need to run more in the session.\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97a075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cali_b_lists = []\n",
    "\n",
    "for i in range(total_trials):\n",
    "    di = {}\n",
    "    for key in list(result.quasi_dists[i].binary_probabilities().keys()):\n",
    "        di.update({key[:num_qubits]: result.quasi_dists[i].binary_probabilities().get(key)})\n",
    "    cali_b_lists.append(di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdea9a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrating_f(cali_b_lists, cali_C_list, num_qubits):\n",
    "    d = 2**num_qubits\n",
    "    num_snapshots = len(cali_C_list)\n",
    "    \n",
    "    f_tilde = 0.\n",
    "    for b_dict, clifford in zip(cali_b_lists, cali_C_list):\n",
    "        F = computing_F(b_dict, clifford, num_qubits)\n",
    "        f_tilde += np.real((d*F - 1) / (d - 1))\n",
    "    \n",
    "    return f_tilde / num_snapshots\n",
    "\n",
    "\n",
    "def computing_F(b_dict, clifford, num_qubits):\n",
    "    zero_state = state_reconstruction('0'*num_qubits)\n",
    "    U = clifford.to_matrix()\n",
    "    \n",
    "    F = 0. + 0.j\n",
    "    denom = 0.\n",
    "    for b_state in list(b_dict.keys()):\n",
    "        F += np.trace(zero_state @ U.T.conj() @ state_reconstruction(b_state) @ U) * b_dict.get(b_state)\n",
    "        denom += b_dict.get(b_state)\n",
    "    return F / denom\n",
    "\n",
    "\n",
    "def state_reconstruction(b_str: str):\n",
    "    '''\n",
    "    '''\n",
    "    zero_state = np.array([[1,0],[0,0]])\n",
    "    one_state = np.array([[0,0], [0,1]])\n",
    "    rho = [1]\n",
    "    for i in b_str:\n",
    "        state_i = zero_state if i=='0' else one_state\n",
    "        rho = np.kron(rho, state_i)\n",
    "    return rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46183d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "f_tilde = calibrating_f(cali_b_lists, cali_C_list, num_qubits)\n",
    "print(f'The calibrated f_tilde is {f_tilde}; while the noiseless reference is {1/(2**num_qubits+1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf8b013",
   "metadata": {},
   "source": [
    "#### II. Perform the standard shadow experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2054f038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit import QuantumCircuit, Parameter, ParameterVector\n",
    "\n",
    "def construct_qcc_circuit(entanglers: list):\n",
    "    '''This function defines the QCC ansatz circuit for VQE. Here we construct exponential blocks using\n",
    "    entanglers from QMF state as a proof of principle demonstration.\n",
    "    \n",
    "    Args:\n",
    "        entanglers: list storing Pauli words for construction of qcc_circuit.\n",
    "        backend: statevector, qasm simulator or a real backend.\n",
    "        truncation: a threshold number to truncate the blocks. Default: None.\n",
    "    Returns:\n",
    "        qcc_circuit\n",
    "    '''\n",
    "    num_blocks = len(entanglers)\n",
    "    # p = ParameterVector('p', num_blocks)\n",
    "    p = [1.16692654, 0.27223177, -0.93402707, -0.92067998, 0.06852241, -0.42444632, -0.41270851, -0.01068001]\n",
    "    \n",
    "    num_qubits = len(entanglers[0])\n",
    "    qcc_circuit = QuantumCircuit(num_qubits)\n",
    "    for i in range(num_blocks):\n",
    "        circuit = QuantumCircuit(num_qubits)\n",
    "        key = entanglers[i]\n",
    "        coupler_map = []\n",
    "        \n",
    "        # We first construct coupler_map according to the key.\n",
    "        for j in range(num_qubits):\n",
    "            if key[num_qubits-1-j] != 'I':\n",
    "                coupler_map.append(j)\n",
    "                \n",
    "        # Then we construct the circuit.\n",
    "        if len(coupler_map) == 1:\n",
    "            # there is no CNOT gate.\n",
    "            c = coupler_map[0]\n",
    "            if key[num_qubits-1-c] == 'X':\n",
    "                circuit.h(c)\n",
    "                circuit.rz(p[i], c)\n",
    "                circuit.h(c)\n",
    "            elif key[num_qubits-1-c] == 'Y':\n",
    "                circuit.rx(-np.pi/2, c)\n",
    "                circuit.rz(p[i], c)\n",
    "                circuit.rx(np.pi/2, c)\n",
    "                \n",
    "            qcc_circuit += circuit\n",
    "        else:\n",
    "            # Here we would need CNOT gate.\n",
    "            for j in coupler_map:\n",
    "                if key[num_qubits-1-j] == 'X':\n",
    "                    circuit.h(j)\n",
    "                elif key[num_qubits-1-j] == 'Y':\n",
    "                    circuit.rx(-np.pi/2, j)\n",
    "                    \n",
    "            for j in range(len(coupler_map) - 1):\n",
    "                circuit.cx(coupler_map[j], coupler_map[j+1])\n",
    "                \n",
    "            param_gate = QuantumCircuit(num_qubits)\n",
    "            param_gate.rz(p[i], coupler_map[-1])\n",
    "            \n",
    "            #qcc_circuit += circuit + param_gate + circuit.inverse()\n",
    "            qcc_circuit.compose(circuit, inplace=True)\n",
    "            qcc_circuit.compose(param_gate, inplace=True)\n",
    "            qcc_circuit.compose(circuit.inverse(), inplace=True)\n",
    "    \n",
    "    return qcc_circuit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fc5724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the ansatz circuit\n",
    "\n",
    "def hf_circ(num_qubits, num_checks):\n",
    "    total_qubits = num_qubits + num_checks\n",
    "    hf_circuit = QuantumCircuit(total_qubits)\n",
    "\n",
    "    hf_circuit.x(0)\n",
    "    hf_circuit.x(1)\n",
    "    hf_circuit.x(2)\n",
    "    hf_circuit.x(3)\n",
    "    \n",
    "    entanglers = ['XXIIIIXY', 'IIXXXYII', 'IXXIXIIY', 'XIIXIXYI',\n",
    "                  'XXIIXYII', 'IXIXIXIY', 'XIXIXIYI', 'IIXXIIXY']\n",
    "\n",
    "    parameterized_circuit = hf_circuit.compose(construct_qcc_circuit(entanglers))\n",
    "    \n",
    "    return parameterized_circuit \n",
    "\n",
    "def hydrogen_shadow_circuit(Clifford, num_qubits):\n",
    "    qc = hf_circ(num_qubits, num_checks=0)\n",
    "    \n",
    "    clifford_circuit = Clifford.to_circuit()\n",
    "    # qc.compose(clifford_circuit, qubits=[0,1,2,3], inplace=True)\n",
    "    qc.barrier()\n",
    "    qc.compose(clifford_circuit, qubits=range(num_qubits), inplace=True)\n",
    "    qc.barrier()\n",
    "    \n",
    "    qc.measure_all()\n",
    "    return qc\n",
    "\n",
    "def hydrogen_shadow_PCS_circuit(Clifford, num_qubits, num_checks):\n",
    "    total_qubits = num_qubits + num_checks\n",
    "    qc = hf_circ(num_qubits, num_checks)\n",
    "\n",
    "    clif_qc = Clifford.to_circuit()\n",
    "    \n",
    "    characters = ['I', 'Z']\n",
    "    strings = [''.join(p) for p in itertools.product(characters, repeat=num_qubits)]\n",
    "    \n",
    "    test_finder = ChecksFinder(num_qubits, clif_qc)\n",
    "    p1_list = []\n",
    "    for string in strings:\n",
    "        string_list = list(string)\n",
    "        result = test_finder.find_checks_sym(pauli_group_elem = string_list)\n",
    "        #print(result.p1_str, result.p2_str)\n",
    "        p1_list.append([result.p1_str, result.p2_str])\n",
    "        \n",
    "    sorted_list = sorted(p1_list, key=lambda s: s[1].count('I'))\n",
    "    pauli_list = sorted_list[-num_qubits -1:-1]\n",
    "    \n",
    "    #\n",
    "    initial_layout = {}\n",
    "    for i in range(0, num_qubits):\n",
    "        initial_layout[i] = [i]\n",
    "\n",
    "    final_layout = {}\n",
    "    for i in range(0, num_qubits):\n",
    "        final_layout[i] = [i]\n",
    "        \n",
    "    #add pauli check on two sides:\n",
    "    #specify the left and right pauli strings\n",
    "    pcs_qc_list = []\n",
    "    sign_list = []\n",
    "    pl_list = []\n",
    "    pr_list = []\n",
    "\n",
    "    for i in range(0, num_checks):\n",
    "        pl = pauli_list[i][0][2:]\n",
    "        pr = pauli_list[i][1][2:]\n",
    "        if i == 0:\n",
    "            temp_qc = add_pauli_checks(clif_qc, pl, pr, initial_layout, final_layout, False, False, False, False, False)\n",
    "            save_qc = add_pauli_checks(clif_qc, pl, pr, initial_layout, final_layout, False, False, False, False, False)\n",
    "            prev_qc = temp_qc\n",
    "        else:\n",
    "            temp_qc = add_pauli_checks(prev_qc, pl, pr, initial_layout, final_layout, False, False, False, False, False)\n",
    "            save_qc = add_pauli_checks(prev_qc, pl, pr, initial_layout, final_layout, False, False, False, False, False) \n",
    "            prev_qc = temp_qc\n",
    "        pl_list.append(pl)\n",
    "        pr_list.append(pr)\n",
    "        sign_list.append(pauli_list[i][0][:2])\n",
    "        pcs_qc_list.append(save_qc)\n",
    "\n",
    "    \n",
    "    qc.compose(pcs_qc_list[-1], qubits=[i for i in range(0, total_qubits)], inplace=True)\n",
    "    \n",
    "    qc.measure_all()\n",
    "    return sign_list, qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6812f9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = 8\n",
    "num_checks = 4\n",
    "C_list = []\n",
    "for i in range(total_trials):\n",
    "    # Clifford = random_clifford(4)\n",
    "    Clifford = random_clifford(num_qubits)\n",
    "    C_list.append(Clifford)\n",
    "circs_list = []\n",
    "signs_list = []\n",
    "for check_id in range(1, num_checks + 1):\n",
    "    circs = []\n",
    "    signs = []\n",
    "    for i in range(total_trials):\n",
    "        print(check_id, i)\n",
    "        sign, circuit = hydrogen_shadow_PCS_circuit(C_list[i], num_qubits, check_id)\n",
    "        signs.append(sign)\n",
    "        circs.append(circuit)\n",
    "    circs_list.append(circs)\n",
    "    signs_list.append(signs)\n",
    "    \n",
    "orign_circs = []\n",
    "for i in range(total_trials):\n",
    "    circuit = hydrogen_shadow_circuit(C_list[i], num_qubits)\n",
    "    orign_circs.append(circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505aa044",
   "metadata": {},
   "outputs": [],
   "source": [
    "circs_list[0][-1].draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70748bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # Save circs_list and origin_circs using pickle\n",
    "# with open('circs_list.pkl', 'wb') as f:\n",
    "#     pickle.dump(circs_list, f)\n",
    "\n",
    "# with open('origin_circs.pkl', 'wb') as f:\n",
    "#     pickle.dump(orign_circs, f)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484bb202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('circs_list.pkl', 'rb') as f:\n",
    "#     circs_list = pickle.load(f)\n",
    "\n",
    "# with open('origin_circs.pkl', 'rb') as f:\n",
    "#     orign_circs = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11874f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(circs_list[0][-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae2cbd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(orign_circs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b320da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_results_reindex(dictionary, qubits, indexes, sign_list):\n",
    "    new_dict = {}\n",
    "    for key in dictionary.keys():\n",
    "        new_key = ''\n",
    "        for i in range(len(key)):\n",
    "            meas_index = i\n",
    "#             if i < len(sign_list):\n",
    "#                 print(key, \"index\", i, key[i], sign_list[meas_index])\n",
    "            if meas_index in indexes and key[i] == sign_list[meas_index]:\n",
    "                #the key equals the sign, keep\n",
    "                new_key = ''\n",
    "                break\n",
    "            if meas_index not in indexes:\n",
    "                new_key += key[i]\n",
    "        if new_key != '':\n",
    "            new_dict[new_key] = dictionary[key]\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b13dc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661f3b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_lists_filtered = []\n",
    "check_id = 1\n",
    "# Submit hardware jobs via Qiskit Runtime;\n",
    "\n",
    "with Session(backend=backend) as session:\n",
    "    sampler = Sampler(session=session, options=options)\n",
    "\n",
    "    # same as the calibration process\n",
    "    job = sampler.run(circs_list[check_id-1], shots=100, initial_layout=[])\n",
    "    print(f\"Job ID: {job.job_id()}\")\n",
    "    print(f\">>> Job Status: {job.status()}\")\n",
    "\n",
    "    result = job.result()\n",
    "\n",
    "    # Close the session only if all jobs are finished\n",
    "    # and you don't need to run more in the session.\n",
    "    session.close()\n",
    "\n",
    "b_lists_check = []\n",
    "\n",
    "for i in range(total_trials):\n",
    "    di = {}\n",
    "    for key in list(result.quasi_dists[i].binary_probabilities().keys()):\n",
    "        di.update({key[:num_qubits + check_id]: result.quasi_dists[i].binary_probabilities().get(key)})\n",
    "    b_lists_check.append(di)\n",
    "\n",
    "\n",
    "filtered_b_lists = []\n",
    "for i in range(total_trials):\n",
    "    bit_list = ['1' if i == '+1' else '0' for i in signs_list[check_id-1][i][check_id - 1::-1]]\n",
    "#     print(bit_list)\n",
    "    filted_dist = filter_results_reindex(b_lists_check[i], num_qubits, [j for j in range(0, check_id)], bit_list)\n",
    "    print(total_counts(filted_dist))\n",
    "    filtered_b_lists.append(filted_dist)\n",
    "b_lists_filtered.append(filtered_b_lists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0db8d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_id = 2\n",
    "# Submit hardware jobs via Qiskit Runtime;\n",
    "\n",
    "with Session(backend=backend) as session:\n",
    "    sampler = Sampler(session=session, options=options)\n",
    "\n",
    "    # same as the calibration process\n",
    "    job = sampler.run(circs_list[check_id-1], shots=100, initial_layout=[])\n",
    "    print(f\"Job ID: {job.job_id()}\")\n",
    "    print(f\">>> Job Status: {job.status()}\")\n",
    "\n",
    "    result = job.result()\n",
    "\n",
    "    # Close the session only if all jobs are finished\n",
    "    # and you don't need to run more in the session.\n",
    "    session.close()\n",
    "\n",
    "b_lists_check = []\n",
    "\n",
    "for i in range(total_trials):\n",
    "    di = {}\n",
    "    for key in list(result.quasi_dists[i].binary_probabilities().keys()):\n",
    "        di.update({key[:num_qubits + check_id]: result.quasi_dists[i].binary_probabilities().get(key)})\n",
    "    b_lists_check.append(di)\n",
    "\n",
    "\n",
    "filtered_b_lists = []\n",
    "for i in range(total_trials):\n",
    "    bit_list = ['1' if i == '+1' else '0' for i in signs_list[check_id-1][i][check_id - 1::-1]]\n",
    "#     print(bit_list)\n",
    "    filted_dist = filter_results_reindex(b_lists_check[i], num_qubits, [j for j in range(0, check_id)], bit_list)\n",
    "    print(total_counts(filted_dist))\n",
    "    filtered_b_lists.append(filted_dist)\n",
    "b_lists_filtered.append(filtered_b_lists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ffdb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "check_id = 3\n",
    "# Submit hardware jobs via Qiskit Runtime;\n",
    "\n",
    "with Session(backend=backend) as session:\n",
    "    sampler = Sampler(session=session, options=options)\n",
    "\n",
    "    # same as the calibration process\n",
    "    job = sampler.run(circs_list[check_id-1], shots=100, initial_layout=[])\n",
    "    print(f\"Job ID: {job.job_id()}\")\n",
    "    print(f\">>> Job Status: {job.status()}\")\n",
    "\n",
    "    result = job.result()\n",
    "\n",
    "    # Close the session only if all jobs are finished\n",
    "    # and you don't need to run more in the session.\n",
    "    session.close()\n",
    "\n",
    "b_lists_check = []\n",
    "\n",
    "for i in range(total_trials):\n",
    "    di = {}\n",
    "    for key in list(result.quasi_dists[i].binary_probabilities().keys()):\n",
    "        di.update({key[:num_qubits + check_id]: result.quasi_dists[i].binary_probabilities().get(key)})\n",
    "    b_lists_check.append(di)\n",
    "\n",
    "\n",
    "filtered_b_lists = []\n",
    "for i in range(total_trials):\n",
    "    bit_list = ['1' if i == '+1' else '0' for i in signs_list[check_id-1][i][check_id - 1::-1]]\n",
    "#     print(bit_list)\n",
    "    filted_dist = filter_results_reindex(b_lists_check[i], num_qubits, [j for j in range(0, check_id)], bit_list)\n",
    "    print(total_counts(filted_dist))\n",
    "    filtered_b_lists.append(filted_dist)\n",
    "b_lists_filtered.append(filtered_b_lists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c520de0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "check_id = 4\n",
    "# Submit hardware jobs via Qiskit Runtime;\n",
    "\n",
    "with Session(backend=backend) as session:\n",
    "    sampler = Sampler(session=session, options=options)\n",
    "\n",
    "    # same as the calibration process\n",
    "    job = sampler.run(circs_list[check_id-1], shots=1024, initial_layout=[])\n",
    "    print(f\"Job ID: {job.job_id()}\")\n",
    "    print(f\">>> Job Status: {job.status()}\")\n",
    "\n",
    "    result = job.result()\n",
    "\n",
    "    # Close the session only if all jobs are finished\n",
    "    # and you don't need to run more in the session.\n",
    "    session.close()\n",
    "\n",
    "b_lists_check = []\n",
    "\n",
    "for i in range(total_trials):\n",
    "    di = {}\n",
    "    for key in list(result.quasi_dists[i].binary_probabilities().keys()):\n",
    "        di.update({key[:num_qubits + check_id]: result.quasi_dists[i].binary_probabilities().get(key)})\n",
    "    b_lists_check.append(di)\n",
    "\n",
    "\n",
    "filtered_b_lists = []\n",
    "for i in range(total_trials):\n",
    "    bit_list = ['1' if i == '+1' else '0' for i in signs_list[check_id-1][i][check_id - 1::-1]]\n",
    "#     print(bit_list)\n",
    "    filted_dist = filter_results_reindex(b_lists_check[i], num_qubits, [j for j in range(0, check_id)], bit_list)\n",
    "    print(total_counts(filted_dist))\n",
    "    filtered_b_lists.append(filted_dist)\n",
    "b_lists_filtered.append(filtered_b_lists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e2dd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit hardware jobs via Qiskit Runtime;\n",
    "\n",
    "with Session(backend=backend) as session:\n",
    "    sampler = Sampler(session=session, options=options)\n",
    "    \n",
    "    # same as the calibration process\n",
    "    job = sampler.run(orign_circs, shots=100, initial_layout=[i for i in range(0, num_qubits)])\n",
    "    print(f\"Job ID: {job.job_id()}\")\n",
    "    print(f\">>> Job Status: {job.status()}\")\n",
    "    \n",
    "    result = job.result()\n",
    "    \n",
    "    # Close the session only if all jobs are finished\n",
    "    # and you don't need to run more in the session.\n",
    "    session.close()\n",
    "    \n",
    "b_lists = []\n",
    "\n",
    "for i in range(total_trials):\n",
    "    di = {}\n",
    "    for key in list(result.quasi_dists[i].binary_probabilities().keys()):\n",
    "        di.update({key[:num_qubits + num_checks]: result.quasi_dists[i].binary_probabilities().get(key)})\n",
    "    b_lists.append(di)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be267d6",
   "metadata": {},
   "source": [
    "Noiseless Experiments on qiskitruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0657001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_ibm_runtime import QiskitRuntimeService, Session, Sampler, Options\n",
    "\n",
    "options = Options(optimization_level=2, resilience_level=1)\n",
    "# backend = service.get_backend(\"ibmq_qasm_simulator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ee4606",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Session(backend=backend) as session:\n",
    "    sampler = Sampler(session=session, options=options)\n",
    "\n",
    "    job = sampler.run(orign_circs, shots=100)\n",
    "    print(f\"Job ID: {job.job_id()}\")\n",
    "    print(f\">>> Job Status: {job.status()}\")\n",
    "    \n",
    "    result = job.result()\n",
    "    \n",
    "    # Close the session only if all jobs are finished\n",
    "    # and you don't need to run more in the session.\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d4bd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def filter_results(dictionary, qubits, indexes, sign_list):\n",
    "    new_dict = {}\n",
    "    for key in dictionary.keys():\n",
    "        new_key = ''\n",
    "        for i in range(len(key)):\n",
    "            meas_index = i\n",
    "            #print(key, meas_index, indexes)\n",
    "            if meas_index in indexes and key[i] == sign_list[meas_index]:\n",
    "                new_key = ''\n",
    "                break\n",
    "            if meas_index not in indexes:\n",
    "                new_key += key[i]\n",
    "        if new_key != '':\n",
    "            new_dict[new_key] = dictionary[key]\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046abcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_lists_noiseless = []\n",
    "\n",
    "for i in range(total_trials):\n",
    "    di = {}\n",
    "    for key in list(result.quasi_dists[i].binary_probabilities().keys()):\n",
    "        di.update({key[:num_qubits]: result.quasi_dists[i].binary_probabilities().get(key)})\n",
    "    b_lists_noiseless.append(di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dd498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_expectation(b_lists, b_lists_checks, b_lists_noiseless, C_list, operator_list, num_qubits, f_tilde):\n",
    "    \"\"\"\n",
    "    Reconstruct a state approximation as an average over all snapshots in the shadow.\n",
    "    Args:\n",
    "        shadow (tuple): A shadow tuple obtained from `calculate_classical_shadow`.\n",
    "        operator (np.ndarray):\n",
    "        num_qubits\n",
    "    Returns:\n",
    "        Numpy array with the reconstructed quantum state.\n",
    "    \"\"\"\n",
    "    num_snapshots = len(b_lists)\n",
    "    \n",
    "    # Averaging over snapshot states.\n",
    "    expectation_list = np.zeros(len(operator_list))\n",
    "    expectation_list_r = np.zeros(len(operator_list))\n",
    "    expectation_list_checks = [np.zeros(len(operator_list)) for i in range(len(b_lists_checks))]\n",
    "    expectation_list_noiseless = np.zeros(len(operator_list))\n",
    "    \n",
    "    for i in range(num_snapshots):\n",
    "        noisy, robust = expectation_snapshot(b_lists[i], C_list[i], operator_list, num_qubits, f_tilde)\n",
    "        expectation_list += noisy\n",
    "        expectation_list_r += robust\n",
    "        \n",
    "        for j in range(len(b_lists_checks)):\n",
    "            check = expectation_snapshot_noiseless(b_lists_checks[j][i], C_list[i], operator_list, num_qubits)\n",
    "            expectation_list_checks[j] += check \n",
    "            \n",
    "        \n",
    "        noiseless = expectation_snapshot_noiseless(b_lists_noiseless[i], C_list[i], operator_list, num_qubits)\n",
    "        expectation_list_noiseless += noiseless\n",
    "        \n",
    "    expectation_list /= num_snapshots\n",
    "    expectation_list_r /= num_snapshots\n",
    "    for j in range(len(b_lists_checks)):\n",
    "        expectation_list_checks[j] /= num_snapshots\n",
    "    expectation_list_noiseless /= num_snapshots\n",
    "    \n",
    "    return expectation_list, expectation_list_r, expectation_list_checks, expectation_list_noiseless\n",
    "\n",
    "\n",
    "def expectation_snapshot(b_dict, clifford, operator_list, num_qubits, f_tilde):\n",
    "    \"\"\"\n",
    "    Helper function for `shadow_state_reconstruction` that reconstructs the overlap estimate from\n",
    "    a single snapshot in a shadow. Implements Eq. (S23) from https://arxiv.org/pdf/2106.16235.pdf\n",
    "    Args:\n",
    "        b_dict (dict): The list of classical outcomes for the snapshot.\n",
    "        clifford: Indices for the applied Pauli measurement.\n",
    "        operator:\n",
    "        num_qubits:\n",
    "    Returns:\n",
    "        Numpy array with the reconstructed snapshot.\n",
    "    \"\"\"\n",
    "    f = 1/(2**num_qubits+1)\n",
    "    # reconstructing the snapshot state from random Clifford measurements\n",
    "    U = clifford.to_matrix()\n",
    "    I = np.eye(2**num_qubits)\n",
    "    \n",
    "    # applying Eq. (S32), note that this expression is built upon random Clifford, so that inverting\n",
    "    # the quantum channel follows Eq. (S29).\n",
    "    snapshot_list = np.zeros(len(operator_list))\n",
    "    snapshot_list_r = np.zeros(len(operator_list))\n",
    "    denom = 0\n",
    "    for b_state in list(b_dict.keys()):\n",
    "        matrix_part = U.conj().T @ state_reconstruction(b_state) @ U\n",
    "        \n",
    "        interm = 1 / f * matrix_part\n",
    "        interm -= (1 / f - 1)/2**num_qubits * I\n",
    "        \n",
    "        interm_r = 1 / f_tilde * matrix_part\n",
    "        interm_r -= (1 / f_tilde - 1) / 2**num_qubits * I\n",
    "        \n",
    "        for index, operator in enumerate(operator_list):\n",
    "            operator_matrix = operator.to_matrix()\n",
    "            snapshot_list[index] += np.real(np.trace(operator_matrix @ interm) * b_dict.get(b_state))\n",
    "            snapshot_list_r[index] += np.real(np.trace(operator_matrix @ interm_r) * b_dict.get(b_state))\n",
    "            \n",
    "        denom += b_dict.get(b_state)\n",
    "    \n",
    "    return snapshot_list / denom, snapshot_list_r / denom\n",
    "\n",
    "\n",
    "def expectation_snapshot_noiseless(b_dict, clifford, operator_list, num_qubits):\n",
    "    \"\"\"\n",
    "    Helper function for `shadow_state_reconstruction` that reconstructs the overlap estimate from\n",
    "    a single snapshot in a shadow. Implements Eq. (S23) from https://arxiv.org/pdf/2106.16235.pdf\n",
    "    Args:\n",
    "        b_dict (dict): The list of classical outcomes for the snapshot.\n",
    "        clifford: Indices for the applied Pauli measurement.\n",
    "        operator:\n",
    "        num_qubits:\n",
    "    Returns:\n",
    "        Numpy array with the reconstructed snapshot.\n",
    "    \"\"\"\n",
    "    f = 1/(2**num_qubits+1)\n",
    "    # reconstructing the snapshot state from random Clifford measurements\n",
    "    U = clifford.to_matrix()\n",
    "    I = np.eye(2**num_qubits)\n",
    "    \n",
    "    # applying Eq. (S32), note that this expression is built upon random Clifford, so that inverting\n",
    "    # the quantum channel follows Eq. (S29).\n",
    "    snapshot_list = np.zeros(len(operator_list))\n",
    "    denom = 0\n",
    "    for b_state in list(b_dict.keys()):\n",
    "        interm = 1/f * U.conj().T @ state_reconstruction(b_state) @ U\n",
    "        interm -= (1/f - 1)/2**num_qubits * I\n",
    "        \n",
    "        for index, operator in enumerate(operator_list):\n",
    "            operator_matrix = operator.to_matrix()\n",
    "            snapshot_list[index] += np.real(np.trace(operator_matrix @ interm) * b_dict.get(b_state))\n",
    "            \n",
    "        denom += b_dict.get(b_state)\n",
    "        \n",
    "    # print('denom =', denom)\n",
    "    return snapshot_list / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e36bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the classical shadows postprocessing to get expectation values;\n",
    "\n",
    "Paulis = ['XXXXXXXX', 'YYYYYYYY', 'XYXYXYXY', 'YXYXYXYX', 'YYYYXXXX', \n",
    "            'XXXXYYYY', 'ZZZZZZZZ', 'ZZZZIIII', 'IIIIZZZZ', 'ZZZZXXXX', 'XXXXZZZZ', 'ZXZXZXZX', 'XZXZXZXZ',\n",
    "             'XXXXIIII', 'IIIIXXXX', 'XXIIXXII']\n",
    "\n",
    "operator_list = []\n",
    "for pauli in Paulis:\n",
    "    operator_list.append(Pauli(pauli))\n",
    "\n",
    "psi = Statevector(hf_circ(num_qubits, num_checks=0))\n",
    "ref_list = []\n",
    "for operator in operator_list:\n",
    "    print(operator)\n",
    "    expect = np.array(psi).T.conj() @ operator.to_matrix() @ np.array(psi)\n",
    "    ref_list.append(expect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a67756",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_runs = 20\n",
    "shadow_range = [100, 400, 1000, 4000, 10000]\n",
    "num_of_checks = 4\n",
    "\n",
    "expectation_shadow = np.zeros((len(shadow_range), len(Paulis), num_of_runs))\n",
    "expectation_shadow_r = np.zeros((len(shadow_range), len(Paulis), num_of_runs))\n",
    "expectation_shadow_check1 = np.zeros((len(shadow_range), len(Paulis), num_of_runs))\n",
    "expectation_shadow_check2 = np.zeros((len(shadow_range), len(Paulis), num_of_runs))\n",
    "expectation_shadow_check3 = np.zeros((len(shadow_range), len(Paulis), num_of_runs))\n",
    "expectation_shadow_check4 = np.zeros((len(shadow_range), len(Paulis), num_of_runs))\n",
    "expectation_shadow_noiseless = np.zeros((len(shadow_range), len(Paulis), num_of_runs))\n",
    "\n",
    "for j, num_snapshots in enumerate(shadow_range):\n",
    "    print('num snapshots = ', num_snapshots)\n",
    "    indices = random.sample(range(total_trials), num_snapshots)\n",
    "\n",
    "    # Partition indices into 'num_of_runs' equally sized chunks\n",
    "    partitions = np.array_split(indices, num_of_runs)\n",
    "    print('paritions', partitions)\n",
    "    print(len(partitions))\n",
    "        \n",
    "    for i, run_indices in enumerate(partitions):\n",
    "        C_sublist = [C_list[k] for k in run_indices]\n",
    "        b_sublists = [b_lists[k] for k in run_indices]\n",
    "        b_sublists_check1 = [b_lists_filtered[0][k] for k in run_indices]\n",
    "        b_sublists_check2 = [b_lists_filtered[1][k] for k in run_indices]\n",
    "        b_sublists_check3 = [b_lists_filtered[2][k] for k in run_indices]\n",
    "        b_sublists_check4 = [b_lists_filtered[3][k] for k in run_indices]\n",
    "        b_sublists_checks = [b_sublists_check1,b_sublists_check2, b_sublists_check3, b_sublists_check4]\n",
    "        b_sublists_noiseless = [b_lists_noiseless[k] for k in run_indices]\n",
    "\n",
    "        expectation_list, expectation_list_r, expectation_list_checks, expectation_list_noiseless = compute_expectation(\n",
    "            b_sublists, b_sublists_checks,  b_sublists_noiseless, C_sublist, operator_list, num_qubits, f_tilde\n",
    "        )\n",
    "\n",
    "        expectation_shadow[j, :, i] = np.real(expectation_list)\n",
    "        expectation_shadow_r[j, :, i] = np.real(expectation_list_r)\n",
    "        expectation_shadow_check1[j, :, i] = np.real(expectation_list_checks[0])\n",
    "        expectation_shadow_check2[j, :, i] = np.real(expectation_list_checks[1])\n",
    "        expectation_shadow_check3[j, :, i] = np.real(expectation_list_checks[2])\n",
    "        expectation_shadow_check4[j, :, i] = np.real(expectation_list_checks[3])\n",
    "        expectation_shadow_noiseless[j, :, i] = np.real(expectation_list_noiseless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9428119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # num_of_runs = 10\n",
    "# num_of_runs = 10\n",
    "# # shadow_range = [5, 10, 40, 100]#, 400]#, 1000]#, 4000]\n",
    "# shadow_range = [100, 400, 800]\n",
    "# expectation_shadow = np.zeros((len(shadow_range), len(Paulis), num_of_runs))\n",
    "# expectation_shadow_r = np.zeros((len(shadow_range), len(Paulis), num_of_runs))\n",
    "# expectation_shadow_check1 = np.zeros((len(shadow_range), len(Paulis), num_of_runs))\n",
    "# expectation_shadow_check2 = np.zeros((len(shadow_range), len(Paulis), num_of_runs))\n",
    "# expectation_shadow_check3 = np.zeros((len(shadow_range), len(Paulis), num_of_runs))\n",
    "# expectation_shadow_check4 = np.zeros((len(shadow_range), len(Paulis), num_of_runs))\n",
    "# expectation_shadow_noiseless = np.zeros((len(shadow_range), len(Paulis), num_of_runs))\n",
    "# for i in range(num_of_runs):\n",
    "#     for j, num_snapshots in enumerate(shadow_range):\n",
    "#         print(f'run # {i}, num snapshots = {num_snapshots}')\n",
    "#         indices = random.sample(range(total_trials), num_snapshots)\n",
    "#         C_sublist = [C_list[k] for k in indices]\n",
    "#         b_sublists = [b_lists[k] for k in indices]\n",
    "#         b_sublists_check1 = [b_lists_filtered[0][k] for k in indices]\n",
    "#         b_sublists_check2 = [b_lists_filtered[1][k] for k in indices]\n",
    "#         b_sublists_check3 = [b_lists_filtered[2][k] for k in indices]\n",
    "#         b_sublists_check4 = [b_lists_filtered[3][k] for k in indices]\n",
    "#         b_sublists_checks = [b_sublists_check1, b_sublists_check2, b_sublists_check3, b_sublists_check4]\n",
    "#         b_sublists_noiseless = [b_lists_noiseless[k] for k in indices]\n",
    "        \n",
    "#         expectation_list, expectation_list_r, expectation_list_checks, expectation_list_noiseless = compute_expectation(\n",
    "#             b_sublists, b_sublists_checks,  b_sublists_noiseless, C_sublist, operator_list, num_qubits, f_tilde\n",
    "#         )\n",
    "        \n",
    "#         print('expectation_list', expectation_list)\n",
    "#         print('expectation_list_r', expectation_list_r)\n",
    "#         print('expectation_list_noiseless', expectation_list_noiseless)\n",
    "        \n",
    "#         expectation_shadow[j, :, i] = np.real(expectation_list)\n",
    "#         expectation_shadow_r[j, :, i] = np.real(expectation_list_r)\n",
    "#         expectation_shadow_check1[j, :, i] = np.real(expectation_list_checks[0])\n",
    "#         expectation_shadow_check2[j, :, i] = np.real(expectation_list_checks[1])\n",
    "#         expectation_shadow_check3[j, :, i] = np.real(expectation_list_checks[2])\n",
    "#         expectation_shadow_check4[j, :, i] = np.real(expectation_list_checks[3])\n",
    "#         expectation_shadow_noiseless[j, :, i] = np.real(expectation_list_noiseless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58f853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ref_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56798df",
   "metadata": {},
   "source": [
    "#### Calculate extrapolated checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8f05d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.polynomial.polynomial import Polynomial\n",
    "\n",
    "medians = [np.median(check, axis=2) for check in [expectation_shadow_check1, expectation_shadow_check2, expectation_shadow_check3, expectation_shadow_check4]]\n",
    "check_numbers = [1, 2, 3, 4]  # Original check layers\n",
    "extrapolation_layers = [8]  # Layers you want to extrapolate to\n",
    "\n",
    "expectation_check_limit = np.zeros((len(extrapolation_layers), len(shadow_range), len(Paulis)))\n",
    "\n",
    "for layer_index, layer in enumerate(extrapolation_layers):\n",
    "    for shadow_size_index in range(len(medians[0])):\n",
    "        for pauli_index in range(medians[0].shape[1]):\n",
    "            expectation_values = [median[shadow_size_index, pauli_index] for median in medians]\n",
    "            polynomial = Polynomial.fit(check_numbers, expectation_values, 1)\n",
    "            extrapolated_value = polynomial(layer) # Extrapolate the value for the current layer\n",
    "            expectation_check_limit[layer_index, shadow_size_index, pauli_index] = extrapolated_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621dd96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(expectation_check_limit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cae5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ref_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8527dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "error = np.zeros(len(shadow_range))\n",
    "error_r = np.zeros(len(shadow_range))\n",
    "error_check1 = np.zeros(len(shadow_range))\n",
    "error_check2 = np.zeros(len(shadow_range))\n",
    "error_check3 = np.zeros(len(shadow_range))\n",
    "error_check4 = np.zeros(len(shadow_range))\n",
    "print(error_check4.shape)\n",
    "print(expectation_shadow_check4.shape)\n",
    "error_noiseless = np.zeros(len(shadow_range))\n",
    "\n",
    "for i in range(len(shadow_range)):\n",
    "    error[i] = np.mean([np.abs(np.median(expectation_shadow[i], axis=1)[j] - ref_list[j]) for j in range(len(ref_list))])\n",
    "    error_r[i] = np.mean([np.abs(np.median(expectation_shadow_r[i], axis=1)[j] - ref_list[j]) for j in range(len(ref_list))])\n",
    "    error_check1[i] = np.mean([np.abs(np.median(expectation_shadow_check1[i], axis=1)[j] - ref_list[j]) for j in range(len(ref_list))])\n",
    "    error_check2[i] = np.mean([np.abs(np.median(expectation_shadow_check2[i], axis=1)[j] - ref_list[j]) for j in range(len(ref_list))])\n",
    "    error_check3[i] = np.mean([np.abs(np.median(expectation_shadow_check3[i], axis=1)[j] - ref_list[j]) for j in range(len(ref_list))])\n",
    "    error_check4[i] = np.mean([np.abs(np.median(expectation_shadow_check4[i], axis=1)[j] - ref_list[j]) for j in range(len(ref_list))])\n",
    "    error_noiseless[i] = np.mean([np.abs(np.median(expectation_shadow_noiseless[i], axis=1)[j] - ref_list[j]) for j in range(len(ref_list))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3716fea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_check_limit = np.zeros((len(extrapolation_layers), len(shadow_range)))\n",
    "\n",
    "for layer_index, layer in enumerate(extrapolation_layers):\n",
    "    for shadow_size_index in range(len(shadow_range)):\n",
    "        # Calculate the mean error for this layer and shadow size across all Pauli indices\n",
    "        error_check_limit[layer_index, shadow_size_index] = np.mean(\n",
    "            [np.abs(expectation_check_limit[layer_index, shadow_size_index, pauli_index] - ref_list[pauli_index]) for pauli_index in range(len(Paulis))]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86fb167",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(error_check_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1a9fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7771c34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(error_check1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b925ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(error_check3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52160d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 4), dpi=100)\n",
    "plt.plot(shadow_range, error, '--o', ms=8, color='tab:orange', label='noisy')\n",
    "plt.plot(shadow_range, error_check1, '--o', ms=8, color='tab:red', label='check1')\n",
    "plt.plot(shadow_range, error_check2, '--o', ms=8, color='tab:purple', label='check2')\n",
    "plt.plot(shadow_range, error_check3, '--o', ms=8, color='tab:olive', label='check3')\n",
    "plt.plot(shadow_range, error_check4, '--o', ms=8, color='tab:pink', label='check4')\n",
    "plt.plot(shadow_range, error_r, '--^', ms=8, color='tab:green', label='robust')\n",
    "plt.plot(shadow_range, error_noiseless, '--x', ms=8, color='tab:blue', label='noiseless')\n",
    "\n",
    "# Plotting each layer of extrapolated checks\n",
    "colors = ['tab:brown', 'tab:gray', 'tab:cyan', 'tab:pink', 'tab:purple']\n",
    "for layer_index, layer in enumerate(extrapolation_layers):\n",
    "    plt.plot(shadow_range, error_check_limit[layer_index, :], '--o', ms=8, color=colors[layer_index % len(colors)], label=f'check {layer} (extrap)')\n",
    "\n",
    "# Adjust the legend to be outside without altering the figure size\n",
    "plt.legend(fontsize=10, loc='upper left', bbox_to_anchor=(1.05, 1))\n",
    "plt.xlabel('Shadow size', fontsize=14)\n",
    "plt.ylabel('Error', fontsize=14)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.tick_params(labelsize=14)\n",
    "\n",
    "# Note: The figure's layout isn't altered with plt.tight_layout() in this case\n",
    "# Saving the figure with bbox_inches='tight' includes the external legend\n",
    "plt.savefig('non_idealchecks.png', dpi=100, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9bd923",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 4), dpi=100)\n",
    "plt.plot(shadow_range, error, '--o', ms=8, color='tab:blue', label='Robust Shadow')\n",
    "plt.legend(fontsize=14, loc='best')\n",
    "plt.xlabel('Shadow size', fontsize=14)\n",
    "plt.ylabel('Error', fontsize=14)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.tick_params(labelsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce02c636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac48211e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pcs_test]",
   "language": "python",
   "name": "conda-env-pcs_test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
